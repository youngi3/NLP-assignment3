{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-03 First Step of Machine Learning: Model and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同学们，今天我们的学习了基本的机器学习概念，相比你已经对机器学习的这些方法有一个基本的认识了。值得说明的是，机器学习不仅仅是一系列方法，更重要的是一种思维体系，即：依据以往的、现有的数据，构建某种方法来解决未见过的问题。而且决策树，贝叶斯只是实现这个目标的一个方法，包括之后的神经网络。很有可能有一天，神经网络也会被淘汰，但是重要的是我们要理解机器学习的目标，就是尽可能的自动化解决未知的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1571556399207&di=4a97dc15ad08dd49d3748d1edf6109b3&imgtype=0&src=http%3A%2F%2Fc.hiphotos.baidu.com%2Fzhidao%2Fwh%3D450%2C600%2Fsign%3Dae742c6aedcd7b89e93932873a146e91%2F5d6034a85edf8db1b16050c40223dd54574e74c7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-1 Programming Review 编程回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Re-code the Linear-Regression Model using scikit-learning(10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>： \n",
    "> + 是否完成线性回归模型 (4')\n",
    "+ 能够进行预测新数据(3')\n",
    "+ 能够进行可视化操作(3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "%matplotlib inline\n",
    "np.random.seed(2042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data = np.random.random((20,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77963915, 0.62110776],\n",
       "       [0.53515387, 0.61704884],\n",
       "       [0.91407081, 0.33408726],\n",
       "       [0.92240829, 0.38852099],\n",
       "       [0.60126364, 0.54772201],\n",
       "       [0.99958684, 0.44942367],\n",
       "       [0.42510865, 0.49465704],\n",
       "       [0.51123914, 0.35731779],\n",
       "       [0.60705171, 0.90040481],\n",
       "       [0.6294306 , 0.38047527],\n",
       "       [0.93740331, 0.05361039],\n",
       "       [0.17145678, 0.87808611],\n",
       "       [0.73331524, 0.49308702],\n",
       "       [0.76886867, 0.11301187],\n",
       "       [0.06397322, 0.88499842],\n",
       "       [0.09252854, 0.00879982],\n",
       "       [0.35131269, 0.74401141],\n",
       "       [0.63686634, 0.27567137],\n",
       "       [0.99076196, 0.39772553],\n",
       "       [0.57501173, 0.45590339]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = random_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77963915],\n",
       "       [0.53515387],\n",
       "       [0.91407081],\n",
       "       [0.92240829],\n",
       "       [0.60126364],\n",
       "       [0.99958684],\n",
       "       [0.42510865],\n",
       "       [0.51123914],\n",
       "       [0.60705171],\n",
       "       [0.6294306 ],\n",
       "       [0.93740331],\n",
       "       [0.17145678],\n",
       "       [0.73331524],\n",
       "       [0.76886867],\n",
       "       [0.06397322],\n",
       "       [0.09252854],\n",
       "       [0.35131269],\n",
       "       [0.63686634],\n",
       "       [0.99076196],\n",
       "       [0.57501173]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = random_data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62110776, 0.61704884, 0.33408726, 0.38852099, 0.54772201,\n",
       "       0.44942367, 0.49465704, 0.35731779, 0.90040481, 0.38047527,\n",
       "       0.05361039, 0.87808611, 0.49308702, 0.11301187, 0.88499842,\n",
       "       0.00879982, 0.74401141, 0.27567137, 0.39772553, 0.45590339])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X.reshape(-1,1),y)  #20个samples,每个sample只有一个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33599349])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6755199359047648"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1386947632958193"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X.reshape(-1,1),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return reg.coef_ * x + reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x230c876a708>]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X,y)\n",
    "plt.plot(X, f(X),color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47392384])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(np.array((0.6)).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Complete the unfinished KNN Model using pure python to solve the previous Line-Regression problem. (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>:\n",
    "> + 是否完成了KNN模型 (4')\n",
    "+ 是否能够预测新的数据 (4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "from scipy.spatial.distance import *\n",
    "def model(X,y):\n",
    "    return ((Xi,yi) for Xi,yi in zip(X,y))\n",
    "def distance(x1,x2):\n",
    "    return abs(x1-x2)\n",
    "def knn_model(X,y,x,k):\n",
    "    most_simmilar = sorted(model(X,y), key = lambda xi: distance(xi[0],x))[:k]\n",
    "    \n",
    "    y_hat = np.mean([y for x,y in most_simmilar])\n",
    "    print(most_simmilar)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.601263638537684, 0.5477220148730689), (0.6070517127922349, 0.9004048149318782), (0.575011734742257, 0.45590338792309193), (0.6294305966511813, 0.38047527136988746), (0.6368663379349846, 0.2756713743844045)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5120353726964663"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model(X,y,0.6,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Re-code the Decision Tree, which could sort the features by salience. (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 是否实现了信息熵 (1' )\n",
    "+ 是否实现了最优先特征点的选择(5')\n",
    "+ 是否实现了持续的特征选则(6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "from collections import Counter\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(elements):\n",
    "    counter = Counter(elements)\n",
    "    probs = [counter[c]/len(elements) for c in set(elements)]\n",
    "    ic(probs)\n",
    "    return -sum(p*np.log(p) for p in probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.75, 0.25]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5623351446188083"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy([1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [1.0]\n",
      "ic| probs: [0.5, 0.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy([0,0]) + entropy([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = {\n",
    "    'gender':['F', 'F', 'F', 'F', 'M', 'M', 'M'],\n",
    "    'income': ['+10', '-10', '+10', '+10', '+10', '+10', '-10'],\n",
    "    'family_number': [1, 1, 2, 1, 1, 1, 2],\n",
    "   # 'pet': [1, 1, 1, 0, 0, 0, 1],\n",
    "    'bought': [1, 1, 1, 0, 0, 0, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame.from_dict(mock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>family_number</th>\n",
       "      <th>bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>-10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender income  family_number  bought\n",
       "0      F    +10              1       1\n",
       "1      F    -10              1       1\n",
       "2      F    +10              2       1\n",
       "3      F    +10              1       0\n",
       "4      M    +10              1       0\n",
       "5      M    +10              1       0\n",
       "6      M    -10              2       1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.25, 0.75]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.198849312913621"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gender entropy\n",
    "entropy([1,1,1,0]) + entropy([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.6, 0.4]\n",
      "ic| probs: [1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6730116670092565"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#incom entropy\n",
    "entropy([1,1,0,0,0]) + entropy([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.6, 0.4]\n",
      "ic| probs: [1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6730116670092565"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#family_number entropy\n",
    "entropy([1,1,0,0,0]) + entropy([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6365141682948128"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第一步特征选择选择income 对于[1,1,0,0,0]信息熵分析\n",
    "#gender entropy\n",
    "entropy([1,1,0]) + entropy([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.75, 0.25]\n",
      "ic| probs: [1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5623351446188083"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#family_numbers entroopy\n",
    "entropy([1,0,0,0]) + entropy([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第二步特征选择选择famliy_numbers\n",
    "#gender entropy\n",
    "entropy([1,0]) + entropy([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最优特征选择\n",
    "def find_the_optimal_spliter(training_data:pd.DataFrame, target :str):\n",
    "    x_fields = set(training_data.columns) - {target}\n",
    "    \n",
    "    spliter = None\n",
    "    min_entropy = float('inf')\n",
    "    \n",
    "    for f in x_fields:\n",
    "        ic(f)\n",
    "        values = set(training_data[f])\n",
    "        ic(values)\n",
    "        for v in values:\n",
    "            spliter_1 = training_data[training_data[f] == v][target].tolist()\n",
    "            ic(spliter_1)\n",
    "            entropy_1 = entropy(spliter_1)\n",
    "            ic(entropy_1)\n",
    "            \n",
    "            spliter_2 = training_data[training_data[f] != v][target].tolist()\n",
    "            ic(spliter_2)\n",
    "            entropy_2 = entropy(spliter_2)\n",
    "            ic(entropy_2)\n",
    "            \n",
    "            entropy_v = entropy_1 + entropy_2\n",
    "            ic(entropy_v)\n",
    "            \n",
    "        if entropy_v <= min_entropy:\n",
    "            min_entropy = entropy_v\n",
    "            spliter = (f,v)\n",
    "        \n",
    "    print('the spliter: {}'.format(spliter))\n",
    "    print('the min_entropy is: {}'.format(min_entropy))\n",
    "    \n",
    "    return spliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| f: 'family_number'\n",
      "ic| values: {1, 2}\n",
      "ic| spliter_1: [1, 1, 0, 0, 0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| entropy_1: 0.6730116670092565\n",
      "ic| spliter_2: [1, 1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_2: -0.0\n",
      "ic| entropy_v: 0.6730116670092565\n",
      "ic| spliter_1: [1, 1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_1: -0.0\n",
      "ic| spliter_2: [1, 1, 0, 0, 0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| entropy_2: 0.6730116670092565\n",
      "ic| entropy_v: 0.6730116670092565\n",
      "ic| f: 'gender'\n",
      "ic| values: {'F', 'M'}\n",
      "ic| spliter_1: [1, 1, 1, 0]\n",
      "ic| probs: [0.25, 0.75]\n",
      "ic| entropy_1: 0.5623351446188083\n",
      "ic| spliter_2: [0, 0, 1]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| entropy_2: 0.6365141682948128\n",
      "ic| entropy_v: 1.198849312913621\n",
      "ic| spliter_1: [0, 0, 1]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| entropy_1: 0.6365141682948128\n",
      "ic| spliter_2: [1, 1, 1, 0]\n",
      "ic| probs: [0.25, 0.75]\n",
      "ic| entropy_2: 0.5623351446188083\n",
      "ic| entropy_v: 1.198849312913621\n",
      "ic| f: 'income'\n",
      "ic| values: {'+10', '-10'}\n",
      "ic| spliter_1: [1, 1, 0, 0, 0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| entropy_1: 0.6730116670092565\n",
      "ic| spliter_2: [1, 1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_2: -0.0\n",
      "ic| entropy_v: 0.6730116670092565\n",
      "ic| spliter_1: [1, 1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_1: -0.0\n",
      "ic| spliter_2: [1, 1, 0, 0, 0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| entropy_2: 0.6730116670092565\n",
      "ic| entropy_v: 0.6730116670092565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the spliter: ('income', '-10')\n",
      "the min_entropy is: 0.6730116670092565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('income', '-10')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_the_optimal_spliter(dataset,'bought')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#持续特征选择，该函数只适用于本次数据集的决策树，不适用于连续二分叉决策树\n",
    "def continue_find_the_optimal(training_data:pd.DataFrame, target :str):\n",
    "    x_fields = set(training_data.columns) - {target}\n",
    "    for i in range(len(x_fields)):\n",
    "        print('第%i层' %(i+1))\n",
    "        spliter = find_the_optimal_spliter(training_data, target)    #每一层寻找最佳feature\n",
    "        spliter_1 = training_data[training_data[spliter[0]] == spliter[1]]   #根据feature拆分数据\n",
    "        print(spliter_1)\n",
    "        spliter_2 = training_data[training_data[spliter[0]] != spliter[1]]   #根据feature拆分数据\n",
    "        print(spliter_2)\n",
    "        if len(set(spliter_1[target].tolist())) != 1:       #判断bought是否全部相同，若不同更新training_data\n",
    "            training_data = spliter_1[spliter_1.columns[spliter_1.columns != spliter[0]]] \n",
    "        if len(set(spliter_2[target].tolist())) != 1:       #判断bought是否全部相同，若不同更新training_data\n",
    "            training_data = spliter_2[spliter_2.columns[spliter_2.columns != spliter[0]]] \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用递归方法实现连续特征选择，该函数适用于连续二分类的决策树\n",
    "my_tree = {}\n",
    "def continue_find_the_optimal_1(training_data, target):\n",
    "    spliter = find_the_optimal_spliter(training_data, target)    #每一层寻找最佳feature\n",
    "\n",
    "    spliter_1 = training_data[training_data[spliter[0]] == spliter[1]]   #根据feature拆分数据\n",
    "    print(spliter_1)\n",
    "    spliter_2 = training_data[training_data[spliter[0]] != spliter[1]]   #根据feature拆分数据\n",
    "    print(spliter_2)\n",
    "    \n",
    "    if len(spliter_1.columns)-1 == 1:\n",
    "        my_tree[spliter[0]] = [set(spliter_1[spliter[0]].tolist()).pop(),set(spliter_1[target].tolist()).pop()]\n",
    "        return\n",
    "        #| set(spliter_1[traget].tolist()) == 1:\n",
    "    if len(spliter_2.columns)-1 == 1:\n",
    "        my_tree[spliter[0]] = [set(spliter_2[spliter[0]].tolist()).pop(),set(spliter_2[target].tolist()).pop()]\n",
    "        return\n",
    "    \n",
    "    training_data_1 = spliter_1[spliter_1.columns[spliter_1.columns != spliter[0]]]\n",
    "    training_data_2 = spliter_2[spliter_2.columns[spliter_2.columns != spliter[0]]]\n",
    "    \n",
    "    if len(set(spliter_1[target].tolist())) != 1:       #判断bought是否全部相同，若不同递归\n",
    "        continue_find_the_optimal_1(training_data_1, target)\n",
    "    else:\n",
    "        my_tree[spliter[0]] = [set(spliter_1[spliter[0]].tolist()).pop(),set(spliter_1[target].tolist()).pop()]\n",
    "    if len(set(spliter_2[target].tolist())) != 1:       #判断bought是否全部相同，若不同递归\n",
    "        continue_find_the_optimal_1(training_data_2, target)\n",
    "    else:\n",
    "        my_tree[spliter[0]] = [set(spliter_2[spliter[0]].tolist()).pop(),set(spliter_2[target].tolist()).pop()]\n",
    "    \n",
    "    return my_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| f: 'family_number'\n",
      "ic| values: {1, 2}\n",
      "ic| spliter_1: [1, 1, 0, 0, 0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| entropy_1: 0.6730116670092565\n",
      "ic| spliter_2: [1, 1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_2: -0.0\n",
      "ic| entropy_v: 0.6730116670092565\n",
      "ic| spliter_1: [1, 1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_1: -0.0\n",
      "ic| spliter_2: [1, 1, 0, 0, 0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| entropy_2: 0.6730116670092565\n",
      "ic| entropy_v: 0.6730116670092565\n",
      "ic| f: 'gender'\n",
      "ic| values: {'F', 'M'}\n",
      "ic| spliter_1: [1, 1, 1, 0]\n",
      "ic| probs: [0.25, 0.75]\n",
      "ic| entropy_1: 0.5623351446188083\n",
      "ic| spliter_2: [0, 0, 1]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| entropy_2: 0.6365141682948128\n",
      "ic| entropy_v: 1.198849312913621\n",
      "ic| spliter_1: [0, 0, 1]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| entropy_1: 0.6365141682948128\n",
      "ic| spliter_2: [1, 1, 1, 0]\n",
      "ic| probs: [0.25, 0.75]\n",
      "ic| entropy_2: 0.5623351446188083\n",
      "ic| entropy_v: 1.198849312913621\n",
      "ic| f: 'income'\n",
      "ic| values: {'+10', '-10'}\n",
      "ic| spliter_1: [1, 1, 0, 0, 0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| entropy_1: 0.6730116670092565\n",
      "ic| spliter_2: [1, 1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_2: -0.0\n",
      "ic| entropy_v: 0.6730116670092565\n",
      "ic| spliter_1: [1, 1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_1: -0.0\n",
      "ic| spliter_2: [1, 1, 0, 0, 0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| entropy_2: 0.6730116670092565\n",
      "ic| entropy_v: 0.6730116670092565\n",
      "ic| f: 'family_number'\n",
      "ic| values: {1, 2}\n",
      "ic| spliter_1: [1, 0, 0, 0]\n",
      "ic| probs: [0.75, 0.25]\n",
      "ic| entropy_1: 0.5623351446188083\n",
      "ic| spliter_2: [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the spliter: ('income', '-10')\n",
      "the min_entropy is: 0.6730116670092565\n",
      "  gender income  family_number  bought\n",
      "1      F    -10              1       1\n",
      "6      M    -10              2       1\n",
      "  gender income  family_number  bought\n",
      "0      F    +10              1       1\n",
      "2      F    +10              2       1\n",
      "3      F    +10              1       0\n",
      "4      M    +10              1       0\n",
      "5      M    +10              1       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [1.0]\n",
      "ic| entropy_2: -0.0\n",
      "ic| entropy_v: 0.5623351446188083\n",
      "ic| spliter_1: [1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_1: -0.0\n",
      "ic| spliter_2: [1, 0, 0, 0]\n",
      "ic| probs: [0.75, 0.25]\n",
      "ic| entropy_2: 0.5623351446188083\n",
      "ic| entropy_v: 0.5623351446188083\n",
      "ic| f: 'gender'\n",
      "ic| values: {'F', 'M'}\n",
      "ic| spliter_1: [1, 1, 0]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| entropy_1: 0.6365141682948128\n",
      "ic| spliter_2: [0, 0]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_2: -0.0\n",
      "ic| entropy_v: 0.6365141682948128\n",
      "ic| spliter_1: [0, 0]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_1: -0.0\n",
      "ic| spliter_2: [1, 1, 0]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| entropy_2: 0.6365141682948128\n",
      "ic| entropy_v: 0.6365141682948128\n",
      "ic| f: 'gender'\n",
      "ic| values: {'F', 'M'}\n",
      "ic| spliter_1: [1, 0]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| entropy_1: 0.6931471805599453\n",
      "ic| spliter_2: [0, 0]\n",
      "ic| probs: [1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the spliter: ('family_number', 2)\n",
      "the min_entropy is: 0.5623351446188083\n",
      "  gender  family_number  bought\n",
      "2      F              2       1\n",
      "  gender  family_number  bought\n",
      "0      F              1       1\n",
      "3      F              1       0\n",
      "4      M              1       0\n",
      "5      M              1       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| entropy_2: -0.0\n",
      "ic| entropy_v: 0.6931471805599453\n",
      "ic| spliter_1: [0, 0]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_1: -0.0\n",
      "ic| spliter_2: [1, 0]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| entropy_2: 0.6931471805599453\n",
      "ic| entropy_v: 0.6931471805599453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the spliter: ('gender', 'M')\n",
      "the min_entropy is: 0.6931471805599453\n",
      "  gender  bought\n",
      "4      M       0\n",
      "5      M       0\n",
      "  gender  bought\n",
      "0      F       1\n",
      "3      F       0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'income': ['-10', 1], 'family_number': [2, 1], 'gender': ['M', 0]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continue_find_the_optimal_1(training_data = dataset, target = 'bought')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Finish the K-Means using 2-D matplotlib (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 是否完成了KMeans模型，基于scikit-learning (3')\n",
    "+ 是否完成了可视化任务（5'）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [random.randint(0,100) for x in range(100)]\n",
    "X2 = [random.randint(0,100) for x in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x230c96c6248>"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X1,X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [[x1,x2] for x1,x2 in zip(X1,X2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = KMeans(n_clusters = 6, max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=500,\n",
       "       n_clusters=6, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 3, 5, 3, 2, 3, 0, 0, 5, 3, 5, 2, 3, 0, 2, 2, 4, 0, 2, 5, 2,\n",
       "       5, 3, 4, 0, 3, 0, 5, 5, 3, 3, 5, 0, 2, 1, 2, 3, 2, 0, 2, 1, 5, 4,\n",
       "       3, 4, 2, 2, 4, 0, 1, 3, 1, 0, 0, 5, 5, 1, 4, 0, 5, 2, 3, 3, 0, 2,\n",
       "       1, 4, 2, 1, 1, 5, 3, 3, 1, 5, 4, 5, 3, 3, 1, 4, 4, 3, 0, 4, 0, 3,\n",
       "       2, 2, 0, 3, 2, 2, 3, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[84.52631579, 16.84210526],\n",
       "       [42.53846154, 48.84615385],\n",
       "       [10.15789474, 35.63157895],\n",
       "       [82.27272727, 75.63636364],\n",
       "       [27.25      , 86.5       ],\n",
       "       [39.4       , 11.93333333]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84.52631579 16.84210526]\n",
      "[42.53846154 48.84615385]\n",
      "[10.15789474 35.63157895]\n",
      "[82.27272727 75.63636364]\n",
      "[27.25 86.5 ]\n",
      "[39.4        11.93333333]\n"
     ]
    }
   ],
   "source": [
    "for center in cluster.cluster_centers_:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label,location in zip(cluster.labels_,training_data):\n",
    "    centers[label].append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['red', 'blue', 'orange', 'purple', 'green', 'yellow']\n",
    "\n",
    "for i,c in enumerate(centers):\n",
    "    for location in centers[c]:\n",
    "        plt.scatter(*location, color = colors[i])\n",
    "        \n",
    "for center in cluster.cluster_centers_:\n",
    "    plt.scatter(*center, s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-2 Question and Answer 问答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What's the *model*? why  all the models are wrong, but some are useful? (5 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 对模型的理解是否正确,对模型的抽象性是否正确(5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型就是对现实世界的内在规则的抽象，所有模型不可能对现实问题百分之百的模拟，总是建立在各种假设条件下的，因为模型在一定的假设条件下\n",
    "考虑主要问题，只要能帮助我们辅助决策，模型就是有用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the underfitting and overfitting? List the reasons that could make model overfitting or underfitting. (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 对过拟合和欠拟合的理解是否正确 (3')\n",
    "+ 对欠拟合产生的原因是否理解正确(2')\n",
    "+ 对过拟合产生的原因是否理解正确(5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+欠拟合：模型没有学得训练集上的特征，即模型对于训练数据表现太差。\n",
    "\n",
    "+过拟合：模型在训练数据上表现良好，但在泛化表现差，即模型在训练数据上学得了数据的局部微小模式。\n",
    "\n",
    "+欠拟合原因：模型太过简单；训练数据的特征不具有代表性；模型的正则项参数过多。\n",
    "\n",
    "+过拟合原因：模型太复杂；训练数据集太少；训练数据集中有噪声，模型把噪声也习得了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What's the precision, recall, AUC, F1, F2score. What are they mainly target on? (12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 对precision, recall, AUC, F1, F2 理解是否正确(6‘)\n",
    "+ 对precision, recall, AUC, F1, F2的使用侧重点是否理解正确 (6’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precison:所有预测是正类中成功预测为正类的比率\n",
    "\n",
    "recall:所有正类中成功预测为正类的比率\n",
    "\n",
    "AUC:area under cover 指ROC曲线(受试者特征曲线)下包的面积，ROC曲线是真正率(召回率)随假正率变化的曲线\n",
    "$$F1score=\\frac{2*precison*recall}{precison+recall}$$\n",
    "\n",
    "$$F2score =\\frac{5*precison*recall}{4*precison+recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preciosn主要侧重于预测正类样本中预测正类的情况，而对于很多正类被预测为负类不关心，即不允许“错杀”，要保证杀掉的都是目标，不能“错杀”良民，例如通过分类器筛选儿童视频，分类器需保证通过分类器的视频几乎都是儿童能观看的。\n",
    "\n",
    "recall主要侧重于所有正类中被成功预测为正类的情况，即你可以把所有样本预测为正类，这样召回率为100%，即允许“错杀”，例如预警机制，宁可警报长鸣，也不能漏掉一次风险。\n",
    "\n",
    "AUC主要用于评估模型分类器的好坏，AUC越大，分类器越好。\n",
    "\n",
    "F1score是用一个指标来衡量模型分类器precision,recall，而且precison,recall权重相同，当precison,reall都大时，F1score越大\n",
    "\n",
    "F2score也是用来衡量模型分类器precison,recall的一个指标，但是F2score把precison的权重调大，表明precison不重要，recall更重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Based on our course and yourself mind, what's the machine learning?  (8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点> 开放式问题，是否能说出来机器学习这种思维方式和传统的分析式编程的区别（8'）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习，是机器根据输入数据，和给定模型，通过优化算法，来自己学得一组满足人类需要的最佳参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. \"正确定义了机器学习模型的评价标准(evaluation)， 问题基本上就已经解决一半\". 这句话是否正确？你是怎么看待的？ (8‘)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点> 开放式问题，主要看能理解评价指标对机器学习模型的重要性."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正确，因为针对不同的问题，机器学习模型的评价指标有很多种，而正确定义机器学习模型的评价指标，才能针对特定问题构建模型。例如：针对视频监控预警问题，如果选择精确率作为模型的评价标准，训练了一个高精确率的模型，虽然模型发出警报，警察抓到的基本全都是小偷，但是当模型没有发出警报时，可能漏报了很多小偷，造成很大的损失。但是如果采用召回率作为模型的评价标准，训练了一个高召回率的模型，虽然模型会经常发出警报，警察会很忙，但是能保证小偷几乎不会漏网。而如果采用F2score作为模型的评价标准，即考虑召回率更重要，训练了一个F2score高的模型，则警察不会太忙，也能保证小偷都被抓住。达到了出手即成功。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-03 Programming Practice 编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In our course and previous practice, we complete some importance components of Decision Tree. In this problem, you need to build a **completed** Decision Tree Model. You show finish a `predicate()` function, which accepts three parameters **<gender, income, family_number>**, and outputs the predicated 'bought': 1 or 0.  (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "#定义结点类\n",
    "class Node:\n",
    "    def __init__(self,attr = None, value = None, result = None, left = None, right = None):\n",
    "        self.attr = attr  #该结点将以哪种feature划分，如‘income’\n",
    "        self.value = value  #该结点对应上一步feature划分的值，如 +10\n",
    "        self.result = result  #对应买不买 0：不买，1：买\n",
    "        self.left = left    #左子树\n",
    "        self.right = right  #右子树\n",
    "#实例化决策树\n",
    "tree = Node('income',None,None,Node('family_numbers',+10,None,Node(None, 2, 1, None, None), Node('gender', '1', None, Node(None, 'M', 0, None,None), Node(None, 'F', '1or0', None, None)))\n",
    "            ,Node(None, -10, 1, None, None))\n",
    "\n",
    "#定义先序遍历来遍历二叉树\n",
    "def propagate(tree):\n",
    "    if tree == None:\n",
    "        return\n",
    "    if tree.result != None:\n",
    "        print((tree.value,tree.result))\n",
    "    propagate(tree.left)\n",
    "    propagate(tree.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "('M', 0)\n",
      "('F', '1or0')\n",
      "(-10, 1)\n"
     ]
    }
   ],
   "source": [
    "propagate(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自动化训练决策树模型，然后根据训练模型预测新实例\n",
    "def predict(training_data, target,gender: str, income: str, family_number: int):  \n",
    "    my_tree = continue_find_the_optimal_1(training_data,target)  #调用决策树模型\n",
    "    print(my_tree)\n",
    "    features = list(my_tree)  #将训练好的决策树的feature存储起来\n",
    "    for feature in features:\n",
    "        value = False\n",
    "        if feature == 'income':\n",
    "            value = my_tree[feature][0] == income\n",
    "        elif feature == 'family_number':\n",
    "            value = my_tree[feature][0] == family_number\n",
    "        else:\n",
    "            value = my_tree[feature][0] == gender\n",
    "        if value:\n",
    "            print('the result is: {}'.format(my_tree[feature][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| f: 'family_number'\n",
      "ic| values: {1, 2}\n",
      "ic| spliter_1: [1, 1, 0, 0, 0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| entropy_1: 0.6730116670092565\n",
      "ic| spliter_2: [1, 1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_2: -0.0\n",
      "ic| entropy_v: 0.6730116670092565\n",
      "ic| spliter_1: [1, 1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_1: -0.0\n",
      "ic| spliter_2: [1, 1, 0, 0, 0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| entropy_2: 0.6730116670092565\n",
      "ic| entropy_v: 0.6730116670092565\n",
      "ic| f: 'gender'\n",
      "ic| values: {'F', 'M'}\n",
      "ic| spliter_1: [1, 1, 1, 0]\n",
      "ic| probs: [0.25, 0.75]\n",
      "ic| entropy_1: 0.5623351446188083\n",
      "ic| spliter_2: [0, 0, 1]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| entropy_2: 0.6365141682948128\n",
      "ic| entropy_v: 1.198849312913621\n",
      "ic| spliter_1: [0, 0, 1]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| entropy_1: 0.6365141682948128\n",
      "ic| spliter_2: [1, 1, 1, 0]\n",
      "ic| probs: [0.25, 0.75]\n",
      "ic| entropy_2: 0.5623351446188083\n",
      "ic| entropy_v: 1.198849312913621\n",
      "ic| f: 'income'\n",
      "ic| values: {'+10', '-10'}\n",
      "ic| spliter_1: [1, 1, 0, 0, 0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| entropy_1: 0.6730116670092565\n",
      "ic| spliter_2: [1, 1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_2: -0.0\n",
      "ic| entropy_v: 0.6730116670092565\n",
      "ic| spliter_1: [1, 1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_1: -0.0\n",
      "ic| spliter_2: [1, 1, 0, 0, 0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| entropy_2: 0.6730116670092565\n",
      "ic| entropy_v: 0.6730116670092565\n",
      "ic| f: 'family_number'\n",
      "ic| values: {1, 2}\n",
      "ic| spliter_1: [1, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the spliter: ('income', '-10')\n",
      "the min_entropy is: 0.6730116670092565\n",
      "  gender income  family_number  bought\n",
      "1      F    -10              1       1\n",
      "6      M    -10              2       1\n",
      "  gender income  family_number  bought\n",
      "0      F    +10              1       1\n",
      "2      F    +10              2       1\n",
      "3      F    +10              1       0\n",
      "4      M    +10              1       0\n",
      "5      M    +10              1       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.75, 0.25]\n",
      "ic| entropy_1: 0.5623351446188083\n",
      "ic| spliter_2: [1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_2: -0.0\n",
      "ic| entropy_v: 0.5623351446188083\n",
      "ic| spliter_1: [1]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_1: -0.0\n",
      "ic| spliter_2: [1, 0, 0, 0]\n",
      "ic| probs: [0.75, 0.25]\n",
      "ic| entropy_2: 0.5623351446188083\n",
      "ic| entropy_v: 0.5623351446188083\n",
      "ic| f: 'gender'\n",
      "ic| values: {'F', 'M'}\n",
      "ic| spliter_1: [1, 1, 0]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| entropy_1: 0.6365141682948128\n",
      "ic| spliter_2: [0, 0]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_2: -0.0\n",
      "ic| entropy_v: 0.6365141682948128\n",
      "ic| spliter_1: [0, 0]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_1: -0.0\n",
      "ic| spliter_2: [1, 1, 0]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| entropy_2: 0.6365141682948128\n",
      "ic| entropy_v: 0.6365141682948128\n",
      "ic| f: 'gender'\n",
      "ic| values: {'F', 'M'}\n",
      "ic| spliter_1: [1, 0]\n",
      "ic| probs: [0.5, 0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the spliter: ('family_number', 2)\n",
      "the min_entropy is: 0.5623351446188083\n",
      "  gender  family_number  bought\n",
      "2      F              2       1\n",
      "  gender  family_number  bought\n",
      "0      F              1       1\n",
      "3      F              1       0\n",
      "4      M              1       0\n",
      "5      M              1       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| entropy_1: 0.6931471805599453\n",
      "ic| spliter_2: [0, 0]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_2: -0.0\n",
      "ic| entropy_v: 0.6931471805599453\n",
      "ic| spliter_1: [0, 0]\n",
      "ic| probs: [1.0]\n",
      "ic| entropy_1: -0.0\n",
      "ic| spliter_2: [1, 0]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| entropy_2: 0.6931471805599453\n",
      "ic| entropy_v: 0.6931471805599453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the spliter: ('gender', 'M')\n",
      "the min_entropy is: 0.6931471805599453\n",
      "  gender  bought\n",
      "4      M       0\n",
      "5      M       0\n",
      "  gender  bought\n",
      "0      F       1\n",
      "3      F       0\n",
      "{'income': ['-10', 1], 'family_number': [2, 1], 'gender': ['M', 0]}\n",
      "the result is: 0\n"
     ]
    }
   ],
   "source": [
    "predict(dataset, 'bought', gender = 'M', income = '+10', family_number = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "没有用结点类和决策树分类器类递归实现决策树的生成和预测，太失败了！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 是否将之前的决策树模型的部分进行合并组装， predicate函数能够顺利运行(8')\n",
    "+ 是够能够输入未曾见过的X变量，例如gender, income, family_number 分别是： <M, -10, 1>, 模型能够预测出结果 (12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 将上一节课(第二节课)的线性回归问题中的Loss函数改成\"绝对值\"，并且改变其偏导的求值方式，观察其结果的变化。(19 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绝对值loss函数：\n",
    "$$loss = \\frac{1}{n}\\sum{|{y-\\hat{y}}|}$$\n",
    "$$loss = \\frac{1}{n}\\sum{|{y-(kx+b)}|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绝对值loss函数对k的偏导：\n",
    "$$\\frac{\\partial{loss}}{\\partial{k}}=\\frac{1}{n}\\sum{(-x_i+x_j)}$$ $$when (y-\\hat{y})>0,-x_i,  when (y-\\hat{y})<=0,x_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define target function\n",
    "def price(rm, k, b):\n",
    "    return k * rm + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "def loss(y, y_hat):\n",
    "    return sum(abs(yi-y_hat_i) for yi, y_hat_i in zip(list(y),list(y_hat)))/len(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_derivative_k(x, y, y_hat):\n",
    "    n = len(y)\n",
    "    gradient = 0\n",
    "    for x_i, y_i, y_hat_i in zip(list(x),list(y),list(y_hat)):\n",
    "        if y_i-y_hat_i>=0:\n",
    "            g = -x_i \n",
    "        else:\n",
    "            g = x_i\n",
    "        gradient += g \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1,the curren_loss: 7.848993463420243, the current_k: -2.2470181945662304\n",
      "iteration: 2,the curren_loss: 7.77400568037349, the current_k: -2.3694827061985846\n",
      "iteration: 3,the curren_loss: 7.699017897326733, the current_k: -2.4919472178309388\n",
      "iteration: 4,the curren_loss: 7.624030114279978, the current_k: -2.614411729463293\n",
      "iteration: 5,the curren_loss: 7.549042331233222, the current_k: -2.736876241095647\n",
      "iteration: 6,the curren_loss: 7.47405454818647, the current_k: -2.8593407527280013\n",
      "iteration: 7,the curren_loss: 7.399066765139713, the current_k: -2.9818052643603554\n",
      "iteration: 8,the curren_loss: 7.324078982092958, the current_k: -3.1042697759927096\n",
      "iteration: 9,the curren_loss: 7.249091199046203, the current_k: -3.2267342876250638\n",
      "iteration: 10,the curren_loss: 7.17410341599945, the current_k: -3.349198799257418\n",
      "iteration: 11,the curren_loss: 7.099115632952691, the current_k: -3.471663310889772\n",
      "iteration: 12,the curren_loss: 7.024127849905938, the current_k: -3.5941278225221263\n",
      "iteration: 13,the curren_loss: 6.949140066859184, the current_k: -3.7165923341544804\n",
      "iteration: 14,the curren_loss: 6.874152283812428, the current_k: -3.8390568457868346\n",
      "iteration: 15,the curren_loss: 6.79916450076567, the current_k: -3.9615213574191888\n",
      "iteration: 16,the curren_loss: 6.724176717718916, the current_k: -4.083985869051543\n",
      "iteration: 17,the curren_loss: 6.649188934672161, the current_k: -4.206450380683897\n",
      "iteration: 18,the curren_loss: 6.574201151625408, the current_k: -4.328914892316251\n",
      "iteration: 19,the curren_loss: 6.499213368578651, the current_k: -4.451379403948605\n",
      "iteration: 20,the curren_loss: 6.424225585531896, the current_k: -4.57384391558096\n",
      "iteration: 21,the curren_loss: 6.34923780248514, the current_k: -4.696308427213314\n",
      "iteration: 22,the curren_loss: 6.274250019438386, the current_k: -4.818772938845668\n",
      "iteration: 23,the curren_loss: 6.199262236391631, the current_k: -4.941237450478022\n",
      "iteration: 24,the curren_loss: 6.124274453344876, the current_k: -5.063701962110376\n",
      "iteration: 25,the curren_loss: 6.0492866702981205, the current_k: -5.18616647374273\n",
      "iteration: 26,the curren_loss: 5.974298887251367, the current_k: -5.308630985375085\n",
      "iteration: 27,the curren_loss: 5.89931110420461, the current_k: -5.431095497007439\n",
      "iteration: 28,the curren_loss: 5.824323321157855, the current_k: -5.553560008639793\n",
      "iteration: 29,the curren_loss: 5.7493355381111, the current_k: -5.676024520272147\n",
      "iteration: 30,the curren_loss: 5.674347755064344, the current_k: -5.798489031904501\n",
      "iteration: 31,the curren_loss: 5.59935997201759, the current_k: -5.920953543536855\n",
      "iteration: 32,the curren_loss: 5.524372188970834, the current_k: -6.04341805516921\n",
      "iteration: 33,the curren_loss: 5.44938440592408, the current_k: -6.165882566801564\n",
      "iteration: 34,the curren_loss: 5.374396622877326, the current_k: -6.288347078433918\n",
      "iteration: 35,the curren_loss: 5.299408839830569, the current_k: -6.410811590066272\n",
      "iteration: 36,the curren_loss: 5.224421056783814, the current_k: -6.533276101698626\n",
      "iteration: 37,the curren_loss: 5.149433273737059, the current_k: -6.65574061333098\n",
      "iteration: 38,the curren_loss: 5.074445490690303, the current_k: -6.778205124963335\n",
      "iteration: 39,the curren_loss: 4.999457707643548, the current_k: -6.900669636595689\n",
      "iteration: 40,the curren_loss: 4.924469924596794, the current_k: -7.023134148228043\n",
      "iteration: 41,the curren_loss: 4.849482141550039, the current_k: -7.145598659860397\n",
      "iteration: 42,the curren_loss: 4.774494358503283, the current_k: -7.268063171492751\n",
      "iteration: 43,the curren_loss: 4.699506575456527, the current_k: -7.390527683125105\n",
      "iteration: 44,the curren_loss: 4.6245187924097735, the current_k: -7.51299219475746\n",
      "iteration: 45,the curren_loss: 4.549531009363017, the current_k: -7.635456706389814\n",
      "iteration: 46,the curren_loss: 4.474543226316262, the current_k: -7.757921218022168\n",
      "iteration: 47,the curren_loss: 4.399555443269507, the current_k: -7.880385729654522\n",
      "iteration: 48,the curren_loss: 4.324567660222752, the current_k: -8.002850241286877\n",
      "iteration: 49,the curren_loss: 4.2495798771759965, the current_k: -8.125314752919232\n",
      "iteration: 50,the curren_loss: 4.17459209412924, the current_k: -8.247779264551587\n",
      "iteration: 51,the curren_loss: 4.0996043110824845, the current_k: -8.370243776183942\n",
      "iteration: 52,the curren_loss: 4.02461652803573, the current_k: -8.492708287816297\n",
      "iteration: 53,the curren_loss: 3.949628744988973, the current_k: -8.615172799448652\n",
      "iteration: 54,the curren_loss: 3.8746409619422173, the current_k: -8.737637311081007\n",
      "iteration: 55,the curren_loss: 3.799653178895462, the current_k: -8.860101822713363\n",
      "iteration: 56,the curren_loss: 3.7246653958487057, the current_k: -8.982566334345718\n",
      "iteration: 57,the curren_loss: 3.6496776128019506, the current_k: -9.105030845978073\n",
      "iteration: 58,the curren_loss: 3.5746898297551946, the current_k: -9.227495357610428\n",
      "iteration: 59,the curren_loss: 3.509786403262203, the current_k: -9.349959869242783\n",
      "iteration: 60,the curren_loss: 3.4640989817874996, the current_k: -9.452432644093397\n",
      "iteration: 61,the curren_loss: 3.429937640736914, the current_k: -9.535090179806222\n",
      "iteration: 62,the curren_loss: 3.39577629968633, the current_k: -9.617747715519046\n",
      "iteration: 63,the curren_loss: 3.3616149586357467, the current_k: -9.70040525123187\n",
      "iteration: 64,the curren_loss: 3.3274536175851623, the current_k: -9.783062786944695\n",
      "iteration: 65,the curren_loss: 3.2932922765345785, the current_k: -9.86572032265752\n",
      "iteration: 66,the curren_loss: 3.259130935483994, the current_k: -9.948377858370344\n",
      "iteration: 67,the curren_loss: 3.2249695944334107, the current_k: -10.031035394083169\n",
      "iteration: 68,the curren_loss: 3.1930880752049466, the current_k: -10.113692929795993\n",
      "iteration: 69,the curren_loss: 3.1724738592290596, the current_k: -10.17790229979117\n",
      "iteration: 70,the curren_loss: 3.152002205096953, the current_k: -10.242111669786345\n",
      "iteration: 71,the curren_loss: 3.1417529026604734, the current_k: -10.288039623628201\n",
      "iteration: 72,the curren_loss: 3.1380591711846693, the current_k: -10.315219511324086\n",
      "iteration: 73,the curren_loss: 3.1343654397088647, the current_k: -10.342399399019971\n",
      "iteration: 74,the curren_loss: 3.13067170823306, the current_k: -10.369579286715856\n",
      "iteration: 75,the curren_loss: 3.126977976757255, the current_k: -10.396759174411741\n",
      "iteration: 76,the curren_loss: 3.123284245281451, the current_k: -10.423939062107626\n",
      "iteration: 77,the curren_loss: 3.119590513805646, the current_k: -10.451118949803512\n",
      "iteration: 78,the curren_loss: 3.115896782329842, the current_k: -10.478298837499397\n",
      "iteration: 79,the curren_loss: 3.112203050854037, the current_k: -10.505478725195282\n",
      "iteration: 80,the curren_loss: 3.1085093193782325, the current_k: -10.532658612891167\n",
      "iteration: 81,the curren_loss: 3.1048155879024284, the current_k: -10.559838500587052\n",
      "iteration: 82,the curren_loss: 3.101121856426623, the current_k: -10.587018388282937\n",
      "iteration: 83,the curren_loss: 3.097428124950819, the current_k: -10.614198275978822\n",
      "iteration: 84,the curren_loss: 3.0937343934750148, the current_k: -10.641378163674707\n",
      "iteration: 85,the curren_loss: 3.09004066199921, the current_k: -10.668558051370592\n",
      "iteration: 86,the curren_loss: 3.086346930523405, the current_k: -10.695737939066477\n",
      "iteration: 87,the curren_loss: 3.0826531990476007, the current_k: -10.722917826762362\n",
      "iteration: 88,the curren_loss: 3.078959467571796, the current_k: -10.750097714458247\n",
      "iteration: 89,the curren_loss: 3.0752657360959916, the current_k: -10.777277602154133\n",
      "iteration: 90,the curren_loss: 3.0715720046201875, the current_k: -10.804457489850018\n",
      "iteration: 91,the curren_loss: 3.067878273144382, the current_k: -10.831637377545903\n",
      "iteration: 92,the curren_loss: 3.0641845416685776, the current_k: -10.858817265241788\n",
      "iteration: 93,the curren_loss: 3.0604908101927735, the current_k: -10.885997152937673\n",
      "iteration: 94,the curren_loss: 3.056797078716969, the current_k: -10.913177040633558\n",
      "iteration: 95,the curren_loss: 3.053103347241164, the current_k: -10.940356928329443\n",
      "iteration: 96,the curren_loss: 3.0494096157653594, the current_k: -10.967536816025328\n",
      "iteration: 97,the curren_loss: 3.045715884289555, the current_k: -10.994716703721213\n",
      "iteration: 98,the curren_loss: 3.0420221528137508, the current_k: -11.021896591417098\n",
      "iteration: 99,the curren_loss: 3.0383284213379467, the current_k: -11.049076479112983\n",
      "iteration: 100,the curren_loss: 3.0346346898621417, the current_k: -11.076256366808868\n",
      "iteration: 101,the curren_loss: 3.0309409583863367, the current_k: -11.103436254504754\n",
      "iteration: 102,the curren_loss: 3.027247226910532, the current_k: -11.130616142200639\n",
      "iteration: 103,the curren_loss: 3.023553495434727, the current_k: -11.157796029896524\n",
      "iteration: 104,the curren_loss: 3.019859763958923, the current_k: -11.184975917592409\n",
      "iteration: 105,the curren_loss: 3.016166032483119, the current_k: -11.212155805288294\n",
      "iteration: 106,the curren_loss: 3.012472301007314, the current_k: -11.239335692984179\n",
      "iteration: 107,the curren_loss: 3.0087785695315095, the current_k: -11.266515580680064\n",
      "iteration: 108,the curren_loss: 3.0050848380557036, the current_k: -11.29369546837595\n",
      "iteration: 109,the curren_loss: 3.0013911065799, the current_k: -11.320875356071834\n",
      "iteration: 110,the curren_loss: 2.9976973751040954, the current_k: -11.34805524376772\n",
      "iteration: 111,the curren_loss: 2.994003643628291, the current_k: -11.375235131463604\n",
      "iteration: 112,the curren_loss: 2.9903099121524863, the current_k: -11.40241501915949\n",
      "iteration: 113,the curren_loss: 2.986616180676682, the current_k: -11.429594906855375\n",
      "iteration: 114,the curren_loss: 2.982922449200877, the current_k: -11.45677479455126\n",
      "iteration: 115,the curren_loss: 2.9792287177250723, the current_k: -11.483954682247145\n",
      "iteration: 116,the curren_loss: 2.9755349862492677, the current_k: -11.51113456994303\n",
      "iteration: 117,the curren_loss: 2.9718412547734636, the current_k: -11.538314457638915\n",
      "iteration: 118,the curren_loss: 2.9681475232976595, the current_k: -11.5654943453348\n",
      "iteration: 119,the curren_loss: 2.964453791821855, the current_k: -11.592674233030685\n",
      "iteration: 120,the curren_loss: 2.9607600603460495, the current_k: -11.61985412072657\n",
      "iteration: 121,the curren_loss: 2.957757776067316, the current_k: -11.647034008422455\n",
      "iteration: 122,the curren_loss: 2.9570864710808835, the current_k: -11.658621113206932\n",
      "iteration: 123,the curren_loss: 2.9564151660944518, the current_k: -11.670208217991409\n",
      "iteration: 124,the curren_loss: 2.955743861108019, the current_k: -11.681795322775885\n",
      "iteration: 125,the curren_loss: 2.9550725561215865, the current_k: -11.693382427560362\n",
      "iteration: 126,the curren_loss: 2.9544012511351547, the current_k: -11.704969532344839\n",
      "iteration: 127,the curren_loss: 2.9537299461487234, the current_k: -11.716556637129315\n",
      "iteration: 128,the curren_loss: 2.9530586411622903, the current_k: -11.728143741913792\n",
      "iteration: 129,the curren_loss: 2.9523873361758586, the current_k: -11.739730846698269\n",
      "iteration: 130,the curren_loss: 2.9517160311894264, the current_k: -11.751317951482745\n",
      "iteration: 131,the curren_loss: 2.951044726202994, the current_k: -11.762905056267222\n",
      "iteration: 132,the curren_loss: 2.950373421216562, the current_k: -11.774492161051699\n",
      "iteration: 133,the curren_loss: 2.949702116230129, the current_k: -11.786079265836175\n",
      "iteration: 134,the curren_loss: 2.9490308112436976, the current_k: -11.797666370620652\n",
      "iteration: 135,the curren_loss: 2.9483595062572654, the current_k: -11.809253475405129\n",
      "iteration: 136,the curren_loss: 2.947688201270833, the current_k: -11.820840580189605\n",
      "iteration: 137,the curren_loss: 2.9470168962844006, the current_k: -11.832427684974082\n",
      "iteration: 138,the curren_loss: 2.9463455912979692, the current_k: -11.844014789758559\n",
      "iteration: 139,the curren_loss: 2.9456742863115366, the current_k: -11.855601894543035\n",
      "iteration: 140,the curren_loss: 2.945002981325104, the current_k: -11.867188999327512\n",
      "iteration: 141,the curren_loss: 2.944331676338672, the current_k: -11.878776104111989\n",
      "iteration: 142,the curren_loss: 2.94366037135224, the current_k: -11.890363208896465\n",
      "iteration: 143,the curren_loss: 2.942989066365807, the current_k: -11.901950313680942\n",
      "iteration: 144,the curren_loss: 2.942317761379375, the current_k: -11.913537418465419\n",
      "iteration: 145,the curren_loss: 2.941646456392943, the current_k: -11.925124523249895\n",
      "iteration: 146,the curren_loss: 2.940975151406511, the current_k: -11.936711628034372\n",
      "iteration: 147,the curren_loss: 2.940303846420079, the current_k: -11.948298732818849\n",
      "iteration: 148,the curren_loss: 2.9396325414336464, the current_k: -11.959885837603325\n",
      "iteration: 149,the curren_loss: 2.938961236447214, the current_k: -11.971472942387802\n",
      "iteration: 150,the curren_loss: 2.9382899314607824, the current_k: -11.983060047172279\n",
      "iteration: 151,the curren_loss: 2.9376186264743507, the current_k: -11.994647151956755\n",
      "iteration: 152,the curren_loss: 2.936947321487918, the current_k: -12.006234256741232\n",
      "iteration: 153,the curren_loss: 2.936276016501485, the current_k: -12.017821361525709\n",
      "iteration: 154,the curren_loss: 2.935604711515053, the current_k: -12.029408466310185\n",
      "iteration: 155,the curren_loss: 2.9349334065286214, the current_k: -12.040995571094662\n",
      "iteration: 156,the curren_loss: 2.934262101542189, the current_k: -12.052582675879139\n",
      "iteration: 157,the curren_loss: 2.933590796555756, the current_k: -12.064169780663615\n",
      "iteration: 158,the curren_loss: 2.932919491569325, the current_k: -12.075756885448092\n",
      "iteration: 159,the curren_loss: 2.9322481865828927, the current_k: -12.087343990232569\n",
      "iteration: 160,the curren_loss: 2.93157688159646, the current_k: -12.098931095017045\n",
      "iteration: 161,the curren_loss: 2.930905576610028, the current_k: -12.110518199801522\n",
      "iteration: 162,the curren_loss: 2.930234271623597, the current_k: -12.122105304585999\n",
      "iteration: 163,the curren_loss: 2.9295629666371634, the current_k: -12.133692409370475\n",
      "iteration: 164,the curren_loss: 2.9288916616507312, the current_k: -12.145279514154952\n",
      "iteration: 165,the curren_loss: 2.9282203566643, the current_k: -12.156866618939429\n",
      "iteration: 166,the curren_loss: 2.9275490516778673, the current_k: -12.168453723723905\n",
      "iteration: 167,the curren_loss: 2.9268777466914346, the current_k: -12.180040828508382\n",
      "iteration: 168,the curren_loss: 2.926206441705003, the current_k: -12.191627933292859\n",
      "iteration: 169,the curren_loss: 2.925535136718571, the current_k: -12.203215038077335\n",
      "iteration: 170,the curren_loss: 2.9248638317321385, the current_k: -12.214802142861812\n",
      "iteration: 171,the curren_loss: 2.9241925267457063, the current_k: -12.226389247646289\n",
      "iteration: 172,the curren_loss: 2.9235212217592736, the current_k: -12.237976352430765\n",
      "iteration: 173,the curren_loss: 2.9228499167728414, the current_k: -12.249563457215242\n",
      "iteration: 174,the curren_loss: 2.9221786117864093, the current_k: -12.261150561999719\n",
      "iteration: 175,the curren_loss: 2.9215073067999766, the current_k: -12.272737666784195\n",
      "iteration: 176,the curren_loss: 2.9208360018135444, the current_k: -12.284324771568672\n",
      "iteration: 177,the curren_loss: 2.920164696827113, the current_k: -12.295911876353149\n",
      "iteration: 178,the curren_loss: 2.919493391840681, the current_k: -12.307498981137625\n",
      "iteration: 179,the curren_loss: 2.9188220868542487, the current_k: -12.319086085922102\n",
      "iteration: 180,the curren_loss: 2.9181507818678165, the current_k: -12.330673190706579\n",
      "iteration: 181,the curren_loss: 2.9174794768813843, the current_k: -12.342260295491055\n",
      "iteration: 182,the curren_loss: 2.916808171894952, the current_k: -12.353847400275532\n",
      "iteration: 183,the curren_loss: 2.916136866908519, the current_k: -12.365434505060009\n",
      "iteration: 184,the curren_loss: 2.9154655619220873, the current_k: -12.377021609844485\n",
      "iteration: 185,the curren_loss: 2.914794256935655, the current_k: -12.388608714628962\n",
      "iteration: 186,the curren_loss: 2.914122951949223, the current_k: -12.400195819413439\n",
      "iteration: 187,the curren_loss: 2.913451646962791, the current_k: -12.411782924197915\n",
      "iteration: 188,the curren_loss: 2.9127803419763585, the current_k: -12.423370028982392\n",
      "iteration: 189,the curren_loss: 2.9121090369899267, the current_k: -12.434957133766869\n",
      "iteration: 190,the curren_loss: 2.9114377320034945, the current_k: -12.446544238551345\n",
      "iteration: 191,the curren_loss: 2.9107664270170623, the current_k: -12.458131343335822\n",
      "iteration: 192,the curren_loss: 2.9106862016124095, the current_k: -12.469718448120299\n",
      "iteration: 193,the curren_loss: 2.9106143709303884, the current_k: -12.46592817947488\n",
      "iteration: 194,the curren_loss: 2.9105425402483656, the current_k: -12.46213791082946\n",
      "iteration: 195,the curren_loss: 2.9107538956299672, the current_k: -12.458347642184041\n",
      "iteration: 196,the curren_loss: 2.9106903007661225, the current_k: -12.469934746968518\n",
      "iteration: 197,the curren_loss: 2.9106184700841, the current_k: -12.466144478323098\n",
      "iteration: 198,the curren_loss: 2.9105466394020785, the current_k: -12.46235420967768\n",
      "iteration: 199,the curren_loss: 2.910741364242871, the current_k: -12.45856394103226\n",
      "iteration: 200,the curren_loss: 2.9106943999198345, the current_k: -12.470151045816737\n",
      "iteration: 201,the curren_loss: 2.9106225692378125, the current_k: -12.466360777171317\n",
      "iteration: 202,the curren_loss: 2.91055073855579, the current_k: -12.462570508525898\n",
      "iteration: 203,the curren_loss: 2.9107288328557765, the current_k: -12.458780239880479\n",
      "iteration: 204,the curren_loss: 2.910698499073547, the current_k: -12.470367344664956\n",
      "iteration: 205,the curren_loss: 2.9106266683915245, the current_k: -12.466577076019536\n",
      "iteration: 206,the curren_loss: 2.910554837709502, the current_k: -12.462786807374117\n",
      "iteration: 207,the curren_loss: 2.910716301468681, the current_k: -12.458996538728698\n",
      "iteration: 208,the curren_loss: 2.9107025982272594, the current_k: -12.470583643513175\n",
      "iteration: 209,the curren_loss: 2.910630767545237, the current_k: -12.466793374867756\n",
      "iteration: 210,the curren_loss: 2.9105589368632154, the current_k: -12.463003106222336\n",
      "iteration: 211,the curren_loss: 2.910703770081585, the current_k: -12.459212837576917\n",
      "iteration: 212,the curren_loss: 2.910706697380972, the current_k: -12.470799942361394\n",
      "iteration: 213,the curren_loss: 2.91063486669895, the current_k: -12.467009673715975\n",
      "iteration: 214,the curren_loss: 2.910563036016927, the current_k: -12.463219405070555\n",
      "iteration: 215,the curren_loss: 2.9106912386944903, the current_k: -12.459429136425136\n",
      "iteration: 216,the curren_loss: 2.910710796534684, the current_k: -12.471016241209613\n",
      "iteration: 217,the curren_loss: 2.910638965852661, the current_k: -12.467225972564194\n",
      "iteration: 218,the curren_loss: 2.9105671351706386, the current_k: -12.463435703918774\n",
      "iteration: 219,the curren_loss: 2.9106787073073943, the current_k: -12.459645435273355\n",
      "iteration: 220,the curren_loss: 2.910714895688396, the current_k: -12.471232540057832\n",
      "iteration: 221,the curren_loss: 2.910643065006374, the current_k: -12.467442271412413\n",
      "iteration: 222,the curren_loss: 2.910571234324351, the current_k: -12.463652002766993\n",
      "iteration: 223,the curren_loss: 2.910666175920299, the current_k: -12.459861734121574\n",
      "iteration: 224,the curren_loss: 2.910718994842108, the current_k: -12.471448838906051\n",
      "iteration: 225,the curren_loss: 2.9106471641600855, the current_k: -12.467658570260632\n",
      "iteration: 226,the curren_loss: 2.910575333478063, the current_k: -12.463868301615213\n",
      "iteration: 227,the curren_loss: 2.9106536445332045, the current_k: -12.460078032969793\n",
      "iteration: 228,the curren_loss: 2.910723093995821, the current_k: -12.47166513775427\n",
      "iteration: 229,the curren_loss: 2.9106512633137975, the current_k: -12.46787486910885\n",
      "iteration: 230,the curren_loss: 2.9105794326317755, the current_k: -12.464084600463432\n",
      "iteration: 231,the curren_loss: 2.910641113146108, the current_k: -12.460294331818012\n",
      "iteration: 232,the curren_loss: 2.9107271931495324, the current_k: -12.471881436602489\n",
      "iteration: 233,the curren_loss: 2.9106553624675096, the current_k: -12.46809116795707\n",
      "iteration: 234,the curren_loss: 2.9105835317854885, the current_k: -12.46430089931165\n",
      "iteration: 235,the curren_loss: 2.910628581759013, the current_k: -12.460510630666231\n",
      "iteration: 236,the curren_loss: 2.9107312923032445, the current_k: -12.472097735450708\n",
      "iteration: 237,the curren_loss: 2.910659461621222, the current_k: -12.468307466805289\n",
      "iteration: 238,the curren_loss: 2.9105876309392, the current_k: -12.46451719815987\n",
      "iteration: 239,the curren_loss: 2.910616050371917, the current_k: -12.46072692951445\n",
      "iteration: 240,the curren_loss: 2.9107353914569574, the current_k: -12.472314034298927\n",
      "iteration: 241,the curren_loss: 2.9106635607749354, the current_k: -12.468523765653508\n",
      "iteration: 242,the curren_loss: 2.9105917300929125, the current_k: -12.464733497008089\n",
      "iteration: 243,the curren_loss: 2.9106035189848227, the current_k: -12.46094322836267\n",
      "iteration: 244,the curren_loss: 2.910739490610669, the current_k: -12.472530333147146\n",
      "iteration: 245,the curren_loss: 2.9106676599286465, the current_k: -12.468740064501727\n",
      "iteration: 246,the curren_loss: 2.910595829246624, the current_k: -12.464949795856308\n",
      "iteration: 247,the curren_loss: 2.9105909875977267, the current_k: -12.461159527210889\n",
      "iteration: 248,the curren_loss: 2.910743589764382, the current_k: -12.472746631995365\n",
      "iteration: 249,the curren_loss: 2.910671759082359, the current_k: -12.468956363349946\n",
      "iteration: 250,the curren_loss: 2.9105999284003365, the current_k: -12.465166094704527\n",
      "iteration: 251,the curren_loss: 2.9105784562106316, the current_k: -12.461375826059108\n",
      "iteration: 252,the curren_loss: 2.910747688918094, the current_k: -12.472962930843584\n",
      "iteration: 253,the curren_loss: 2.9106758582360714, the current_k: -12.469172662198165\n",
      "iteration: 254,the curren_loss: 2.910604027554049, the current_k: -12.465382393552746\n",
      "iteration: 255,the curren_loss: 2.910565924823537, the current_k: -12.461592124907327\n",
      "iteration: 256,the curren_loss: 2.9107517880718055, the current_k: -12.473179229691803\n",
      "iteration: 257,the curren_loss: 2.9106799573897835, the current_k: -12.469388961046384\n",
      "iteration: 258,the curren_loss: 2.9106081267077615, the current_k: -12.465598692400965\n",
      "iteration: 259,the curren_loss: 2.9105533934364405, the current_k: -12.461808423755546\n",
      "iteration: 260,the curren_loss: 2.9107558872255175, the current_k: -12.473395528540022\n",
      "iteration: 261,the curren_loss: 2.910684056543496, the current_k: -12.469605259894603\n",
      "iteration: 262,the curren_loss: 2.9106122258614735, the current_k: -12.465814991249184\n",
      "iteration: 263,the curren_loss: 2.910540862049346, the current_k: -12.462024722603765\n",
      "iteration: 264,the curren_loss: 2.9107599863792304, the current_k: -12.473611827388241\n",
      "iteration: 265,the curren_loss: 2.9106881556972075, the current_k: -12.469821558742822\n",
      "iteration: 266,the curren_loss: 2.9106163250151846, the current_k: -12.466031290097403\n",
      "iteration: 267,the curren_loss: 2.9105444943331635, the current_k: -12.462241021451984\n",
      "iteration: 268,the curren_loss: 2.9107479218620287, the current_k: -12.458450752806565\n",
      "iteration: 269,the curren_loss: 2.91069225485092, the current_k: -12.470037857591041\n",
      "iteration: 270,the curren_loss: 2.910620424168898, the current_k: -12.466247588945622\n",
      "iteration: 271,the curren_loss: 2.910548593486876, the current_k: -12.462457320300203\n",
      "iteration: 272,the curren_loss: 2.910735390474934, the current_k: -12.458667051654784\n",
      "iteration: 273,the curren_loss: 2.910696354004632, the current_k: -12.47025415643926\n",
      "iteration: 274,the curren_loss: 2.910624523322611, the current_k: -12.466463887793841\n",
      "iteration: 275,the curren_loss: 2.9105526926405885, the current_k: -12.462673619148422\n",
      "iteration: 276,the curren_loss: 2.910722859087838, the current_k: -12.458883350503003\n",
      "iteration: 277,the curren_loss: 2.9107004531583445, the current_k: -12.47047045528748\n",
      "iteration: 278,the curren_loss: 2.9106286224763225, the current_k: -12.46668018664206\n",
      "iteration: 279,the curren_loss: 2.9105567917943, the current_k: -12.462889917996641\n",
      "iteration: 280,the curren_loss: 2.910710327700743, the current_k: -12.459099649351222\n",
      "iteration: 281,the curren_loss: 2.9107045523120574, the current_k: -12.470686754135698\n",
      "iteration: 282,the curren_loss: 2.9106327216300345, the current_k: -12.46689648549028\n",
      "iteration: 283,the curren_loss: 2.9105608909480125, the current_k: -12.46310621684486\n",
      "iteration: 284,the curren_loss: 2.9106977963136473, the current_k: -12.45931594819944\n",
      "iteration: 285,the curren_loss: 2.910708651465769, the current_k: -12.470903052983918\n",
      "iteration: 286,the curren_loss: 2.9106368207837465, the current_k: -12.467112784338498\n",
      "iteration: 287,the curren_loss: 2.910564990101725, the current_k: -12.46332251569308\n",
      "iteration: 288,the curren_loss: 2.9106852649265513, the current_k: -12.45953224704766\n",
      "iteration: 289,the curren_loss: 2.9107127506194805, the current_k: -12.471119351832137\n",
      "iteration: 290,the curren_loss: 2.9106409199374585, the current_k: -12.467329083186717\n",
      "iteration: 291,the curren_loss: 2.910569089255437, the current_k: -12.463538814541298\n",
      "iteration: 292,the curren_loss: 2.910672733539457, the current_k: -12.459748545895879\n",
      "iteration: 293,the curren_loss: 2.910716849773194, the current_k: -12.471335650680356\n",
      "iteration: 294,the curren_loss: 2.9106450190911706, the current_k: -12.467545382034936\n",
      "iteration: 295,the curren_loss: 2.9105731884091486, the current_k: -12.463755113389517\n",
      "iteration: 296,the curren_loss: 2.9106602021523615, the current_k: -12.459964844744098\n",
      "iteration: 297,the curren_loss: 2.910720948926906, the current_k: -12.471551949528575\n",
      "iteration: 298,the curren_loss: 2.9106491182448844, the current_k: -12.467761680883156\n",
      "iteration: 299,the curren_loss: 2.9105772875628615, the current_k: -12.463971412237736\n",
      "iteration: 300,the curren_loss: 2.9106476707652655, the current_k: -12.460181143592317\n",
      "iteration: 301,the curren_loss: 2.9107250480806184, the current_k: -12.471768248376794\n",
      "iteration: 302,the curren_loss: 2.910653217398596, the current_k: -12.467977979731375\n",
      "iteration: 303,the curren_loss: 2.9105813867165735, the current_k: -12.464187711085955\n",
      "iteration: 304,the curren_loss: 2.910635139378171, the current_k: -12.460397442440536\n",
      "iteration: 305,the curren_loss: 2.9107291472343304, the current_k: -12.471984547225013\n",
      "iteration: 306,the curren_loss: 2.910657316552308, the current_k: -12.468194278579594\n",
      "iteration: 307,the curren_loss: 2.9105854858702864, the current_k: -12.464404009934174\n",
      "iteration: 308,the curren_loss: 2.910622607991075, the current_k: -12.460613741288755\n",
      "iteration: 309,the curren_loss: 2.9107332463880424, the current_k: -12.472200846073232\n",
      "iteration: 310,the curren_loss: 2.91066141570602, the current_k: -12.468410577427813\n",
      "iteration: 311,the curren_loss: 2.910589585023998, the current_k: -12.464620308782393\n",
      "iteration: 312,the curren_loss: 2.9106100766039793, the current_k: -12.460830040136974\n",
      "iteration: 313,the curren_loss: 2.910737345541755, the current_k: -12.472417144921451\n",
      "iteration: 314,the curren_loss: 2.9106655148597325, the current_k: -12.468626876276032\n",
      "iteration: 315,the curren_loss: 2.9105936841777105, the current_k: -12.464836607630613\n",
      "iteration: 316,the curren_loss: 2.910597545216884, the current_k: -12.461046338985193\n",
      "iteration: 317,the curren_loss: 2.9107414446954665, the current_k: -12.47263344376967\n",
      "iteration: 318,the curren_loss: 2.910669614013445, the current_k: -12.46884317512425\n",
      "iteration: 319,the curren_loss: 2.910597783331422, the current_k: -12.465052906478832\n",
      "iteration: 320,the curren_loss: 2.910585013829789, the current_k: -12.461262637833412\n",
      "iteration: 321,the curren_loss: 2.910745543849179, the current_k: -12.472849742617889\n",
      "iteration: 322,the curren_loss: 2.910673713167157, the current_k: -12.46905947397247\n",
      "iteration: 323,the curren_loss: 2.910601882485135, the current_k: -12.46526920532705\n",
      "iteration: 324,the curren_loss: 2.910572482442693, the current_k: -12.461478936681631\n",
      "iteration: 325,the curren_loss: 2.9107496430028914, the current_k: -12.473066041466108\n",
      "iteration: 326,the curren_loss: 2.9106778123208694, the current_k: -12.469275772820689\n",
      "iteration: 327,the curren_loss: 2.9106059816388465, the current_k: -12.46548550417527\n",
      "iteration: 328,the curren_loss: 2.910559951055597, the current_k: -12.46169523552985\n",
      "iteration: 329,the curren_loss: 2.910753742156604, the current_k: -12.473282340314327\n",
      "iteration: 330,the curren_loss: 2.9106819114745814, the current_k: -12.469492071668908\n",
      "iteration: 331,the curren_loss: 2.910610080792559, the current_k: -12.465701803023489\n",
      "iteration: 332,the curren_loss: 2.910547419668503, the current_k: -12.46191153437807\n",
      "iteration: 333,the curren_loss: 2.910757841310316, the current_k: -12.473498639162546\n",
      "iteration: 334,the curren_loss: 2.910686010628293, the current_k: -12.469708370517127\n",
      "iteration: 335,the curren_loss: 2.910614179946271, the current_k: -12.465918101871708\n",
      "iteration: 336,the curren_loss: 2.9105423492642495, the current_k: -12.462127833226289\n",
      "iteration: 337,the curren_loss: 2.910754479481187, the current_k: -12.45833756458087\n",
      "iteration: 338,the curren_loss: 2.910690109782006, the current_k: -12.469924669365346\n",
      "iteration: 339,the curren_loss: 2.910618279099983, the current_k: -12.466134400719927\n",
      "iteration: 340,the curren_loss: 2.910546448417961, the current_k: -12.462344132074508\n",
      "iteration: 341,the curren_loss: 2.910741948094091, the current_k: -12.458553863429088\n",
      "iteration: 342,the curren_loss: 2.9106942089357175, the current_k: -12.470140968213565\n",
      "iteration: 343,the curren_loss: 2.910622378253696, the current_k: -12.466350699568146\n",
      "iteration: 344,the curren_loss: 2.910550547571674, the current_k: -12.462560430922727\n",
      "iteration: 345,the curren_loss: 2.910729416706995, the current_k: -12.458770162277307\n",
      "iteration: 346,the curren_loss: 2.9106983080894304, the current_k: -12.470357267061784\n",
      "iteration: 347,the curren_loss: 2.9106264774074075, the current_k: -12.466566998416365\n",
      "iteration: 348,the curren_loss: 2.9105546467253856, the current_k: -12.462776729770946\n",
      "iteration: 349,the curren_loss: 2.9107168853199004, the current_k: -12.458986461125527\n",
      "iteration: 350,the curren_loss: 2.9107024072431424, the current_k: -12.470573565910003\n",
      "iteration: 351,the curren_loss: 2.9106305765611205, the current_k: -12.466783297264584\n",
      "iteration: 352,the curren_loss: 2.910558745879098, the current_k: -12.462993028619165\n",
      "iteration: 353,the curren_loss: 2.910704353932805, the current_k: -12.459202759973746\n",
      "iteration: 354,the curren_loss: 2.9107065063968545, the current_k: -12.470789864758222\n",
      "iteration: 355,the curren_loss: 2.9106346757148325, the current_k: -12.466999596112803\n",
      "iteration: 356,the curren_loss: 2.91056284503281, the current_k: -12.463209327467384\n",
      "iteration: 357,the curren_loss: 2.9106918225457092, the current_k: -12.459419058821965\n",
      "iteration: 358,the curren_loss: 2.910710605550567, the current_k: -12.471006163606441\n",
      "iteration: 359,the curren_loss: 2.910638774868544, the current_k: -12.467215894961022\n",
      "iteration: 360,the curren_loss: 2.910566944186523, the current_k: -12.463425626315603\n",
      "iteration: 361,the curren_loss: 2.910679291158614, the current_k: -12.459635357670184\n",
      "iteration: 362,the curren_loss: 2.910714704704279, the current_k: -12.47122246245466\n",
      "iteration: 363,the curren_loss: 2.9106428740222565, the current_k: -12.467432193809241\n",
      "iteration: 364,the curren_loss: 2.9105710433402345, the current_k: -12.463641925163822\n",
      "iteration: 365,the curren_loss: 2.9106667597715186, the current_k: -12.459851656518403\n",
      "iteration: 366,the curren_loss: 2.9107188038579914, the current_k: -12.47143876130288\n",
      "iteration: 367,the curren_loss: 2.9106469731759694, the current_k: -12.46764849265746\n",
      "iteration: 368,the curren_loss: 2.910575142493947, the current_k: -12.463858224012041\n",
      "iteration: 369,the curren_loss: 2.910654228384423, the current_k: -12.460067955366622\n",
      "iteration: 370,the curren_loss: 2.9107229030117034, the current_k: -12.471655060151098\n",
      "iteration: 371,the curren_loss: 2.9106510723296815, the current_k: -12.46786479150568\n",
      "iteration: 372,the curren_loss: 2.9105792416476595, the current_k: -12.46407452286026\n",
      "iteration: 373,the curren_loss: 2.9106416969973274, the current_k: -12.46028425421484\n",
      "iteration: 374,the curren_loss: 2.910727002165416, the current_k: -12.471871358999318\n",
      "iteration: 375,the curren_loss: 2.9106551714833935, the current_k: -12.468081090353898\n",
      "iteration: 376,the curren_loss: 2.910583340801371, the current_k: -12.46429082170848\n",
      "iteration: 377,the curren_loss: 2.9106291656102323, the current_k: -12.46050055306306\n",
      "iteration: 378,the curren_loss: 2.910731101319128, the current_k: -12.472087657847537\n",
      "iteration: 379,the curren_loss: 2.910659270637106, the current_k: -12.468297389202117\n",
      "iteration: 380,the curren_loss: 2.910587439955083, the current_k: -12.464507120556698\n",
      "iteration: 381,the curren_loss: 2.9106166342231368, the current_k: -12.460716851911279\n",
      "iteration: 382,the curren_loss: 2.91073520047284, the current_k: -12.472303956695756\n",
      "iteration: 383,the curren_loss: 2.910663369790818, the current_k: -12.468513688050336\n",
      "iteration: 384,the curren_loss: 2.910591539108796, the current_k: -12.464723419404917\n",
      "iteration: 385,the curren_loss: 2.910604102836042, the current_k: -12.460933150759498\n",
      "iteration: 386,the curren_loss: 2.9107392996265524, the current_k: -12.472520255543975\n",
      "iteration: 387,the curren_loss: 2.9106674689445304, the current_k: -12.468729986898555\n",
      "iteration: 388,the curren_loss: 2.910595638262508, the current_k: -12.464939718253136\n",
      "iteration: 389,the curren_loss: 2.910591571448947, the current_k: -12.461149449607717\n",
      "iteration: 390,the curren_loss: 2.9107433987802644, the current_k: -12.472736554392194\n",
      "iteration: 391,the curren_loss: 2.910671568098243, the current_k: -12.468946285746775\n",
      "iteration: 392,the curren_loss: 2.9105997374162205, the current_k: -12.465156017101355\n",
      "iteration: 393,the curren_loss: 2.9105790400618514, the current_k: -12.461365748455936\n",
      "iteration: 394,the curren_loss: 2.910747497933977, the current_k: -12.472952853240413\n",
      "iteration: 395,the curren_loss: 2.910675667251955, the current_k: -12.469162584594994\n",
      "iteration: 396,the curren_loss: 2.9106038365699325, the current_k: -12.465372315949574\n",
      "iteration: 397,the curren_loss: 2.910566508674756, the current_k: -12.461582047304155\n",
      "iteration: 398,the curren_loss: 2.9107515970876885, the current_k: -12.473169152088632\n",
      "iteration: 399,the curren_loss: 2.910679766405667, the current_k: -12.469378883443213\n",
      "iteration: 400,the curren_loss: 2.910607935723645, the current_k: -12.465588614797793\n",
      "iteration: 401,the curren_loss: 2.91055397728766, the current_k: -12.461798346152374\n",
      "iteration: 402,the curren_loss: 2.910755696241402, the current_k: -12.473385450936851\n",
      "iteration: 403,the curren_loss: 2.910683865559379, the current_k: -12.469595182291432\n",
      "iteration: 404,the curren_loss: 2.9106120348773565, the current_k: -12.465804913646013\n",
      "iteration: 405,the curren_loss: 2.9105414459005647, the current_k: -12.462014645000593\n",
      "iteration: 406,the curren_loss: 2.910759795395114, the current_k: -12.47360174978507\n",
      "iteration: 407,the curren_loss: 2.9106879647130914, the current_k: -12.46981148113965\n",
      "iteration: 408,the curren_loss: 2.910616134031069, the current_k: -12.466021212494232\n",
      "iteration: 409,the curren_loss: 2.910544303349047, the current_k: -12.462230943848812\n",
      "iteration: 410,the curren_loss: 2.910748505713248, the current_k: -12.458440675203393\n",
      "iteration: 411,the curren_loss: 2.9106920638668035, the current_k: -12.47002777998787\n",
      "iteration: 412,the curren_loss: 2.910620233184781, the current_k: -12.46623751134245\n",
      "iteration: 413,the curren_loss: 2.9105484025027595, the current_k: -12.462447242697031\n",
      "iteration: 414,the curren_loss: 2.910735974326153, the current_k: -12.458656974051612\n",
      "iteration: 415,the curren_loss: 2.910696163020516, the current_k: -12.470244078836089\n",
      "iteration: 416,the curren_loss: 2.910624332338494, the current_k: -12.46645381019067\n",
      "iteration: 417,the curren_loss: 2.910552501656471, the current_k: -12.46266354154525\n",
      "iteration: 418,the curren_loss: 2.910723442939058, the current_k: -12.458873272899831\n",
      "iteration: 419,the curren_loss: 2.9107002621742284, the current_k: -12.470460377684308\n",
      "iteration: 420,the curren_loss: 2.9106284314922055, the current_k: -12.466670109038889\n",
      "iteration: 421,the curren_loss: 2.9105566008101835, the current_k: -12.46287984039347\n",
      "iteration: 422,the curren_loss: 2.9107109115519627, the current_k: -12.45908957174805\n",
      "iteration: 423,the curren_loss: 2.91070436132794, the current_k: -12.470676676532527\n",
      "iteration: 424,the curren_loss: 2.9106325306459175, the current_k: -12.466886407887108\n",
      "iteration: 425,the curren_loss: 2.9105606999638955, the current_k: -12.463096139241689\n",
      "iteration: 426,the curren_loss: 2.910698380164867, the current_k: -12.45930587059627\n",
      "iteration: 427,the curren_loss: 2.910708460481653, the current_k: -12.470892975380746\n",
      "iteration: 428,the curren_loss: 2.91063662979963, the current_k: -12.467102706735327\n",
      "iteration: 429,the curren_loss: 2.9105647991176085, the current_k: -12.463312438089908\n",
      "iteration: 430,the curren_loss: 2.9106858487777716, the current_k: -12.459522169444488\n",
      "iteration: 431,the curren_loss: 2.9107125596353645, the current_k: -12.471109274228965\n",
      "iteration: 432,the curren_loss: 2.9106407289533425, the current_k: -12.467319005583546\n",
      "iteration: 433,the curren_loss: 2.91056889827132, the current_k: -12.463528736938127\n",
      "iteration: 434,the curren_loss: 2.910673317390676, the current_k: -12.459738468292707\n",
      "iteration: 435,the curren_loss: 2.9107166587890765, the current_k: -12.471325573077184\n",
      "iteration: 436,the curren_loss: 2.910644828107055, the current_k: -12.467535304431765\n",
      "iteration: 437,the curren_loss: 2.9105729974250325, the current_k: -12.463745035786346\n",
      "iteration: 438,the curren_loss: 2.9106607860035805, the current_k: -12.459954767140927\n",
      "iteration: 439,the curren_loss: 2.910720757942789, the current_k: -12.471541871925403\n",
      "iteration: 440,the curren_loss: 2.910648927260767, the current_k: -12.467751603279984\n",
      "iteration: 441,the curren_loss: 2.910577096578745, the current_k: -12.463961334634565\n",
      "iteration: 442,the curren_loss: 2.9106482546164854, the current_k: -12.460171065989146\n",
      "iteration: 443,the curren_loss: 2.9107248570965014, the current_k: -12.471758170773622\n",
      "iteration: 444,the curren_loss: 2.9106530264144785, the current_k: -12.467967902128203\n",
      "iteration: 445,the curren_loss: 2.9105811957324565, the current_k: -12.464177633482784\n",
      "iteration: 446,the curren_loss: 2.9106357232293902, the current_k: -12.460387364837365\n",
      "iteration: 447,the curren_loss: 2.910728956250214, the current_k: -12.471974469621841\n",
      "iteration: 448,the curren_loss: 2.9106571255681915, the current_k: -12.468184200976422\n",
      "iteration: 449,the curren_loss: 2.910585294886169, the current_k: -12.464393932331003\n",
      "iteration: 450,the curren_loss: 2.910623191842295, the current_k: -12.460603663685584\n",
      "iteration: 451,the curren_loss: 2.910733055403926, the current_k: -12.47219076847006\n",
      "iteration: 452,the curren_loss: 2.9106612247219035, the current_k: -12.468400499824641\n",
      "iteration: 453,the curren_loss: 2.910589394039882, the current_k: -12.464610231179222\n",
      "iteration: 454,the curren_loss: 2.910610660455199, the current_k: -12.460819962533803\n",
      "iteration: 455,the curren_loss: 2.910737154557638, the current_k: -12.47240706731828\n",
      "iteration: 456,the curren_loss: 2.9106653238756164, the current_k: -12.46861679867286\n",
      "iteration: 457,the curren_loss: 2.9105934931935935, the current_k: -12.464826530027441\n",
      "iteration: 458,the curren_loss: 2.9105981290681036, the current_k: -12.461036261382022\n",
      "iteration: 459,the curren_loss: 2.910741253711351, the current_k: -12.472623366166498\n",
      "iteration: 460,the curren_loss: 2.9106694230293284, the current_k: -12.46883309752108\n",
      "iteration: 461,the curren_loss: 2.9105975923473055, the current_k: -12.46504282887566\n",
      "iteration: 462,the curren_loss: 2.910585597681009, the current_k: -12.46125256023024\n",
      "iteration: 463,the curren_loss: 2.910745352865063, the current_k: -12.472839665014718\n",
      "iteration: 464,the curren_loss: 2.9106735221830404, the current_k: -12.469049396369298\n",
      "iteration: 465,the curren_loss: 2.910601691501017, the current_k: -12.46525912772388\n",
      "iteration: 466,the curren_loss: 2.910573066293913, the current_k: -12.46146885907846\n",
      "iteration: 467,the curren_loss: 2.9107494520187744, the current_k: -12.473055963862937\n",
      "iteration: 468,the curren_loss: 2.910677621336753, the current_k: -12.469265695217517\n",
      "iteration: 469,the curren_loss: 2.9106057906547305, the current_k: -12.465475426572098\n",
      "iteration: 470,the curren_loss: 2.910560534906818, the current_k: -12.461685157926679\n",
      "iteration: 471,the curren_loss: 2.9107535511724874, the current_k: -12.473272262711156\n",
      "iteration: 472,the curren_loss: 2.910681720490465, the current_k: -12.469481994065736\n",
      "iteration: 473,the curren_loss: 2.910609889808442, the current_k: -12.465691725420317\n",
      "iteration: 474,the curren_loss: 2.910548003519722, the current_k: -12.461901456774898\n",
      "iteration: 475,the curren_loss: 2.910757650326199, the current_k: -12.473488561559375\n",
      "iteration: 476,the curren_loss: 2.9106858196441774, the current_k: -12.469698292913955\n",
      "iteration: 477,the curren_loss: 2.9106139889621545, the current_k: -12.465908024268536\n",
      "iteration: 478,the curren_loss: 2.9105421582801325, the current_k: -12.462117755623117\n",
      "iteration: 479,the curren_loss: 2.9107550633324055, the current_k: -12.458327486977698\n",
      "iteration: 480,the curren_loss: 2.9106899187978894, the current_k: -12.469914591762175\n",
      "iteration: 481,the curren_loss: 2.910618088115867, the current_k: -12.466124323116755\n",
      "iteration: 482,the curren_loss: 2.9105462574338454, the current_k: -12.462334054471336\n",
      "iteration: 483,the curren_loss: 2.9107425319453104, the current_k: -12.458543785825917\n",
      "iteration: 484,the curren_loss: 2.9106940179516014, the current_k: -12.470130890610394\n",
      "iteration: 485,the curren_loss: 2.9106221872695786, the current_k: -12.466340621964974\n",
      "iteration: 486,the curren_loss: 2.9105503565875566, the current_k: -12.462550353319555\n",
      "iteration: 487,the curren_loss: 2.9107300005582153, the current_k: -12.458760084674136\n",
      "iteration: 488,the curren_loss: 2.9106981171053135, the current_k: -12.470347189458613\n",
      "iteration: 489,the curren_loss: 2.910626286423292, the current_k: -12.466556920813193\n",
      "iteration: 490,the curren_loss: 2.910554455741269, the current_k: -12.462766652167774\n",
      "iteration: 491,the curren_loss: 2.9107174691711197, the current_k: -12.458976383522355\n",
      "iteration: 492,the curren_loss: 2.910702216259026, the current_k: -12.470563488306832\n",
      "iteration: 493,the curren_loss: 2.9106303855770035, the current_k: -12.466773219661412\n",
      "iteration: 494,the curren_loss: 2.910558554894981, the current_k: -12.462982951015993\n",
      "iteration: 495,the curren_loss: 2.9107049377840246, the current_k: -12.459192682370574\n",
      "iteration: 496,the curren_loss: 2.910706315412738, the current_k: -12.47077978715505\n",
      "iteration: 497,the curren_loss: 2.910634484730715, the current_k: -12.466989518509632\n",
      "iteration: 498,the curren_loss: 2.910562654048694, the current_k: -12.463199249864212\n",
      "iteration: 499,the curren_loss: 2.910692406396929, the current_k: -12.459408981218793\n",
      "iteration: 500,the curren_loss: 2.9107104145664504, the current_k: -12.47099608600327\n",
      "iteration: 501,the curren_loss: 2.9106385838844284, the current_k: -12.46720581735785\n",
      "iteration: 502,the curren_loss: 2.910566753202406, the current_k: -12.463415548712431\n",
      "iteration: 503,the curren_loss: 2.910679875009834, the current_k: -12.459625280067012\n",
      "iteration: 504,the curren_loss: 2.910714513720162, the current_k: -12.471212384851489\n",
      "iteration: 505,the curren_loss: 2.91064268303814, the current_k: -12.46742211620607\n",
      "iteration: 506,the curren_loss: 2.9105708523561185, the current_k: -12.46363184756065\n",
      "iteration: 507,the curren_loss: 2.910667343622738, the current_k: -12.459841578915231\n",
      "iteration: 508,the curren_loss: 2.9107186128738745, the current_k: -12.471428683699708\n",
      "iteration: 509,the curren_loss: 2.9106467821918525, the current_k: -12.467638415054289\n",
      "iteration: 510,the curren_loss: 2.9105749515098305, the current_k: -12.46384814640887\n",
      "iteration: 511,the curren_loss: 2.910654812235643, the current_k: -12.46005787776345\n",
      "iteration: 512,the curren_loss: 2.9107227120275874, the current_k: -12.471644982547927\n",
      "iteration: 513,the curren_loss: 2.910650881345565, the current_k: -12.467854713902508\n",
      "iteration: 514,the curren_loss: 2.910579050663542, the current_k: -12.464064445257089\n",
      "iteration: 515,the curren_loss: 2.910642280848548, the current_k: -12.46027417661167\n",
      "iteration: 516,the curren_loss: 2.9107268111812994, the current_k: -12.471861281396146\n",
      "iteration: 517,the curren_loss: 2.9106549804992765, the current_k: -12.468071012750727\n",
      "iteration: 518,the curren_loss: 2.910583149817255, the current_k: -12.464280744105308\n",
      "iteration: 519,the curren_loss: 2.910629749461452, the current_k: -12.460490475459888\n",
      "iteration: 520,the curren_loss: 2.910730910335011, the current_k: -12.472077580244365\n",
      "iteration: 521,the curren_loss: 2.910659079652989, the current_k: -12.468287311598946\n",
      "iteration: 522,the curren_loss: 2.9105872489709674, the current_k: -12.464497042953527\n",
      "iteration: 523,the curren_loss: 2.9106172180743566, the current_k: -12.460706774308107\n",
      "iteration: 524,the curren_loss: 2.910735009488724, the current_k: -12.472293879092584\n",
      "iteration: 525,the curren_loss: 2.9106631788067014, the current_k: -12.468503610447165\n",
      "iteration: 526,the curren_loss: 2.9105913481246795, the current_k: -12.464713341801746\n",
      "iteration: 527,the curren_loss: 2.910604686687262, the current_k: -12.460923073156327\n",
      "iteration: 528,the curren_loss: 2.910739108642436, the current_k: -12.472510177940803\n",
      "iteration: 529,the curren_loss: 2.9106672779604144, the current_k: -12.468719909295384\n",
      "iteration: 530,the curren_loss: 2.910595447278392, the current_k: -12.464929640649965\n",
      "iteration: 531,the curren_loss: 2.910592155300166, the current_k: -12.461139372004546\n",
      "iteration: 532,the curren_loss: 2.9107432077961475, the current_k: -12.472726476789022\n",
      "iteration: 533,the curren_loss: 2.910671377114126, the current_k: -12.468936208143603\n",
      "iteration: 534,the curren_loss: 2.9105995464321035, the current_k: -12.465145939498184\n",
      "iteration: 535,the curren_loss: 2.910579623913071, the current_k: -12.461355670852765\n",
      "iteration: 536,the curren_loss: 2.910747306949861, the current_k: -12.472942775637241\n",
      "iteration: 537,the curren_loss: 2.9106754762678384, the current_k: -12.469152506991822\n",
      "iteration: 538,the curren_loss: 2.9106036455858164, the current_k: -12.465362238346403\n",
      "iteration: 539,the curren_loss: 2.9105670925259757, the current_k: -12.461571969700984\n",
      "iteration: 540,the curren_loss: 2.9107514061035724, the current_k: -12.47315907448546\n",
      "iteration: 541,the curren_loss: 2.9106795754215504, the current_k: -12.469368805840041\n",
      "iteration: 542,the curren_loss: 2.9106077447395284, the current_k: -12.465578537194622\n",
      "iteration: 543,the curren_loss: 2.91055456113888, the current_k: -12.461788268549203\n",
      "iteration: 544,the curren_loss: 2.910755505257285, the current_k: -12.47337537333368\n",
      "iteration: 545,the curren_loss: 2.910683674575262, the current_k: -12.46958510468826\n",
      "iteration: 546,the curren_loss: 2.91061184389324, the current_k: -12.465794836042841\n",
      "iteration: 547,the curren_loss: 2.9105420297517846, the current_k: -12.462004567397422\n",
      "iteration: 548,the curren_loss: 2.9107596044109973, the current_k: -12.473591672181898\n",
      "iteration: 549,the curren_loss: 2.910687773728975, the current_k: -12.46980140353648\n",
      "iteration: 550,the curren_loss: 2.910615943046953, the current_k: -12.46601113489106\n",
      "iteration: 551,the curren_loss: 2.91054411236493, the current_k: -12.46222086624564\n",
      "iteration: 552,the curren_loss: 2.9107490895644683, the current_k: -12.458430597600222\n",
      "iteration: 553,the curren_loss: 2.910691872882687, the current_k: -12.470017702384698\n",
      "iteration: 554,the curren_loss: 2.9106200422006645, the current_k: -12.466227433739279\n",
      "iteration: 555,the curren_loss: 2.910548211518642, the current_k: -12.46243716509386\n",
      "iteration: 556,the curren_loss: 2.910736558177373, the current_k: -12.45864689644844\n",
      "iteration: 557,the curren_loss: 2.9106959720363994, the current_k: -12.470234001232917\n",
      "iteration: 558,the curren_loss: 2.910624141354378, the current_k: -12.466443732587498\n",
      "iteration: 559,the curren_loss: 2.9105523106723545, the current_k: -12.462653463942079\n",
      "iteration: 560,the curren_loss: 2.9107240267902776, the current_k: -12.45886319529666\n",
      "iteration: 561,the curren_loss: 2.910700071190111, the current_k: -12.470450300081136\n",
      "iteration: 562,the curren_loss: 2.91062824050809, the current_k: -12.466660031435717\n",
      "iteration: 563,the curren_loss: 2.910556409826067, the current_k: -12.462869762790298\n",
      "iteration: 564,the curren_loss: 2.910711495403182, the current_k: -12.459079494144879\n",
      "iteration: 565,the curren_loss: 2.910704170343824, the current_k: -12.470666598929355\n",
      "iteration: 566,the curren_loss: 2.9106323396618015, the current_k: -12.466876330283936\n",
      "iteration: 567,the curren_loss: 2.910560508979779, the current_k: -12.463086061638517\n",
      "iteration: 568,the curren_loss: 2.910698964016087, the current_k: -12.459295792993098\n",
      "iteration: 569,the curren_loss: 2.910708269497536, the current_k: -12.470882897777575\n",
      "iteration: 570,the curren_loss: 2.910636438815514, the current_k: -12.467092629132155\n",
      "iteration: 571,the curren_loss: 2.910564608133491, the current_k: -12.463302360486736\n",
      "iteration: 572,the curren_loss: 2.9106864326289914, the current_k: -12.459512091841317\n",
      "iteration: 573,the curren_loss: 2.910712368651248, the current_k: -12.471099196625794\n",
      "iteration: 574,the curren_loss: 2.910640537969226, the current_k: -12.467308927980374\n",
      "iteration: 575,the curren_loss: 2.9105687072872035, the current_k: -12.463518659334955\n",
      "iteration: 576,the curren_loss: 2.910673901241896, the current_k: -12.459728390689536\n",
      "iteration: 577,the curren_loss: 2.910716467804961, the current_k: -12.471315495474013\n",
      "iteration: 578,the curren_loss: 2.910644637122938, the current_k: -12.467525226828593\n",
      "iteration: 579,the curren_loss: 2.910572806440916, the current_k: -12.463734958183174\n",
      "iteration: 580,the curren_loss: 2.9106613698548007, the current_k: -12.459944689537755\n",
      "iteration: 581,the curren_loss: 2.9107205669586724, the current_k: -12.471531794322232\n",
      "iteration: 582,the curren_loss: 2.91064873627665, the current_k: -12.467741525676812\n",
      "iteration: 583,the curren_loss: 2.910576905594628, the current_k: -12.463951257031393\n",
      "iteration: 584,the curren_loss: 2.910648838467705, the current_k: -12.460160988385974\n",
      "iteration: 585,the curren_loss: 2.9107246661123845, the current_k: -12.47174809317045\n",
      "iteration: 586,the curren_loss: 2.910652835430363, the current_k: -12.467957824525032\n",
      "iteration: 587,the curren_loss: 2.91058100474834, the current_k: -12.464167555879612\n",
      "iteration: 588,the curren_loss: 2.9106363070806096, the current_k: -12.460377287234193\n",
      "iteration: 589,the curren_loss: 2.9107287652660974, the current_k: -12.47196439201867\n",
      "iteration: 590,the curren_loss: 2.9106569345840745, the current_k: -12.46817412337325\n",
      "iteration: 591,the curren_loss: 2.910585103902053, the current_k: -12.464383854727831\n",
      "iteration: 592,the curren_loss: 2.910623775693515, the current_k: -12.460593586082412\n",
      "iteration: 593,the curren_loss: 2.910732864419809, the current_k: -12.472180690866889\n",
      "iteration: 594,the curren_loss: 2.9106610337377865, the current_k: -12.46839042222147\n",
      "iteration: 595,the curren_loss: 2.910589203055765, the current_k: -12.46460015357605\n",
      "iteration: 596,the curren_loss: 2.910611244306419, the current_k: -12.460809884930631\n",
      "iteration: 597,the curren_loss: 2.9107369635735214, the current_k: -12.472396989715108\n",
      "iteration: 598,the curren_loss: 2.9106651328914994, the current_k: -12.468606721069689\n",
      "iteration: 599,the curren_loss: 2.9105933022094774, the current_k: -12.46481645242427\n",
      "iteration: 600,the curren_loss: 2.9105987129193234, the current_k: -12.46102618377885\n",
      "iteration: 601,the curren_loss: 2.9107410627272334, the current_k: -12.472613288563327\n",
      "iteration: 602,the curren_loss: 2.910669232045212, the current_k: -12.468823019917908\n",
      "iteration: 603,the curren_loss: 2.9105974013631895, the current_k: -12.465032751272489\n",
      "iteration: 604,the curren_loss: 2.9105861815322287, the current_k: -12.46124248262707\n",
      "iteration: 605,the curren_loss: 2.910745161880946, the current_k: -12.472829587411546\n",
      "iteration: 606,the curren_loss: 2.910673331198924, the current_k: -12.469039318766127\n",
      "iteration: 607,the curren_loss: 2.910601500516901, the current_k: -12.465249050120708\n",
      "iteration: 608,the curren_loss: 2.9105736501451327, the current_k: -12.461458781475288\n",
      "iteration: 609,the curren_loss: 2.910749261034658, the current_k: -12.473045886259765\n",
      "iteration: 610,the curren_loss: 2.910677430352636, the current_k: -12.469255617614346\n",
      "iteration: 611,the curren_loss: 2.9106055996706135, the current_k: -12.465465348968927\n",
      "iteration: 612,the curren_loss: 2.9105611187580376, the current_k: -12.461675080323507\n",
      "iteration: 613,the curren_loss: 2.9107533601883704, the current_k: -12.473262185107984\n",
      "iteration: 614,the curren_loss: 2.9106815295063475, the current_k: -12.469471916462565\n",
      "iteration: 615,the curren_loss: 2.9106096988243264, the current_k: -12.465681647817146\n",
      "iteration: 616,the curren_loss: 2.910548587370942, the current_k: -12.461891379171727\n",
      "iteration: 617,the curren_loss: 2.9107574593420824, the current_k: -12.473478483956203\n",
      "iteration: 618,the curren_loss: 2.910685628660061, the current_k: -12.469688215310784\n",
      "iteration: 619,the curren_loss: 2.910613797978038, the current_k: -12.465897946665365\n",
      "iteration: 620,the curren_loss: 2.910541967296016, the current_k: -12.462107678019946\n",
      "iteration: 621,the curren_loss: 2.9107556471836253, the current_k: -12.458317409374526\n",
      "iteration: 622,the curren_loss: 2.9106897278137724, the current_k: -12.469904514159003\n",
      "iteration: 623,the curren_loss: 2.9106178971317505, the current_k: -12.466114245513584\n",
      "iteration: 624,the curren_loss: 2.910546066449728, the current_k: -12.462323976868165\n",
      "iteration: 625,the curren_loss: 2.9107431157965302, the current_k: -12.458533708222745\n",
      "iteration: 626,the curren_loss: 2.9106938269674854, the current_k: -12.470120813007222\n",
      "iteration: 627,the curren_loss: 2.9106219962854625, the current_k: -12.466330544361803\n",
      "iteration: 628,the curren_loss: 2.9105501656034396, the current_k: -12.462540275716384\n",
      "iteration: 629,the curren_loss: 2.9107305844094347, the current_k: -12.458750007070964\n",
      "iteration: 630,the curren_loss: 2.910697926121197, the current_k: -12.470337111855441\n",
      "iteration: 631,the curren_loss: 2.9106260954391745, the current_k: -12.466546843210022\n",
      "iteration: 632,the curren_loss: 2.9105542647571525, the current_k: -12.462756574564603\n",
      "iteration: 633,the curren_loss: 2.9107180530223395, the current_k: -12.458966305919184\n",
      "iteration: 634,the curren_loss: 2.910702025274909, the current_k: -12.47055341070366\n",
      "iteration: 635,the curren_loss: 2.9106301945928865, the current_k: -12.466763142058241\n",
      "iteration: 636,the curren_loss: 2.9105583639108654, the current_k: -12.462972873412822\n",
      "iteration: 637,the curren_loss: 2.9107055216352435, the current_k: -12.459182604767403\n",
      "iteration: 638,the curren_loss: 2.910706124428622, the current_k: -12.47076970955188\n",
      "iteration: 639,the curren_loss: 2.9106342937465994, the current_k: -12.46697944090646\n",
      "iteration: 640,the curren_loss: 2.910562463064577, the current_k: -12.46318917226104\n",
      "iteration: 641,the curren_loss: 2.9106929902481484, the current_k: -12.459398903615622\n",
      "iteration: 642,the curren_loss: 2.910710223582333, the current_k: -12.470986008400098\n",
      "iteration: 643,the curren_loss: 2.9106383929003115, the current_k: -12.467195739754679\n",
      "iteration: 644,the curren_loss: 2.910566562218289, the current_k: -12.46340547110926\n",
      "iteration: 645,the curren_loss: 2.910680458861053, the current_k: -12.45961520246384\n",
      "iteration: 646,the curren_loss: 2.9107143227360464, the current_k: -12.471202307248317\n",
      "iteration: 647,the curren_loss: 2.910642492054024, the current_k: -12.467412038602898\n",
      "iteration: 648,the curren_loss: 2.9105706613720006, the current_k: -12.463621769957479\n",
      "iteration: 649,the curren_loss: 2.9106679274739578, the current_k: -12.45983150131206\n",
      "iteration: 650,the curren_loss: 2.910718421889758, the current_k: -12.471418606096536\n",
      "iteration: 651,the curren_loss: 2.9106465912077355, the current_k: -12.467628337451117\n",
      "iteration: 652,the curren_loss: 2.9105747605257135, the current_k: -12.463838068805698\n",
      "iteration: 653,the curren_loss: 2.910655396086862, the current_k: -12.460047800160279\n",
      "iteration: 654,the curren_loss: 2.9107225210434704, the current_k: -12.471634904944755\n",
      "iteration: 655,the curren_loss: 2.910650690361448, the current_k: -12.467844636299336\n",
      "iteration: 656,the curren_loss: 2.9105788596794264, the current_k: -12.464054367653917\n",
      "iteration: 657,the curren_loss: 2.910642864699767, the current_k: -12.460264099008498\n",
      "iteration: 658,the curren_loss: 2.9107266201971824, the current_k: -12.471851203792975\n",
      "iteration: 659,the curren_loss: 2.91065478951516, the current_k: -12.468060935147555\n",
      "iteration: 660,the curren_loss: 2.910582958833138, the current_k: -12.464270666502136\n",
      "iteration: 661,the curren_loss: 2.910630333312672, the current_k: -12.460480397856717\n",
      "iteration: 662,the curren_loss: 2.9107307193508953, the current_k: -12.472067502641194\n",
      "iteration: 663,the curren_loss: 2.9106588886688725, the current_k: -12.468277233995774\n",
      "iteration: 664,the curren_loss: 2.91058705798685, the current_k: -12.464486965350355\n",
      "iteration: 665,the curren_loss: 2.910617801925577, the current_k: -12.460696696704936\n",
      "iteration: 666,the curren_loss: 2.910734818504607, the current_k: -12.472283801489413\n",
      "iteration: 667,the curren_loss: 2.9106629878225845, the current_k: -12.468493532843993\n",
      "iteration: 668,the curren_loss: 2.910591157140563, the current_k: -12.464703264198574\n",
      "iteration: 669,the curren_loss: 2.9106052705384813, the current_k: -12.460912995553155\n",
      "iteration: 670,the curren_loss: 2.9107389176583185, the current_k: -12.472500100337632\n",
      "iteration: 671,the curren_loss: 2.9106670869762974, the current_k: -12.468709831692212\n",
      "iteration: 672,the curren_loss: 2.910595256294275, the current_k: -12.464919563046793\n",
      "iteration: 673,the curren_loss: 2.9105927391513857, the current_k: -12.461129294401374\n",
      "iteration: 674,the curren_loss: 2.9107430168120314, the current_k: -12.47271639918585\n",
      "iteration: 675,the curren_loss: 2.910671186130009, the current_k: -12.468926130540432\n",
      "iteration: 676,the curren_loss: 2.910599355447987, the current_k: -12.465135861895012\n",
      "iteration: 677,the curren_loss: 2.91058020776429, the current_k: -12.461345593249593\n",
      "iteration: 678,the curren_loss: 2.910747115965744, the current_k: -12.47293269803407\n",
      "iteration: 679,the curren_loss: 2.9106752852837214, the current_k: -12.46914242938865\n",
      "iteration: 680,the curren_loss: 2.910603454601699, the current_k: -12.465352160743231\n",
      "iteration: 681,the curren_loss: 2.9105676763771946, the current_k: -12.461561892097812\n",
      "iteration: 682,the curren_loss: 2.9107512151194554, the current_k: -12.473148996882289\n",
      "iteration: 683,the curren_loss: 2.9106793844374335, the current_k: -12.46935872823687\n",
      "iteration: 684,the curren_loss: 2.910607553755411, the current_k: -12.46556845959145\n",
      "iteration: 685,the curren_loss: 2.9105551449900995, the current_k: -12.461778190946031\n",
      "iteration: 686,the curren_loss: 2.910755314273168, the current_k: -12.473365295730508\n",
      "iteration: 687,the curren_loss: 2.9106834835911455, the current_k: -12.469575027085089\n",
      "iteration: 688,the curren_loss: 2.9106116529091244, the current_k: -12.46578475843967\n",
      "iteration: 689,the curren_loss: 2.9105426136030044, the current_k: -12.46199448979425\n",
      "iteration: 690,the curren_loss: 2.91075941342688, the current_k: -12.473581594578727\n",
      "iteration: 691,the curren_loss: 2.910687582744858, the current_k: -12.469791325933308\n",
      "iteration: 692,the curren_loss: 2.9106157520628364, the current_k: -12.466001057287889\n",
      "iteration: 693,the curren_loss: 2.910543921380813, the current_k: -12.46221078864247\n",
      "iteration: 694,the curren_loss: 2.910749673415688, the current_k: -12.45842051999705\n",
      "iteration: 695,the curren_loss: 2.9106916818985704, the current_k: -12.470007624781527\n",
      "iteration: 696,the curren_loss: 2.910619851216548, the current_k: -12.466217356136108\n",
      "iteration: 697,the curren_loss: 2.9105480205345255, the current_k: -12.462427087490688\n",
      "iteration: 698,the curren_loss: 2.9107371420285917, the current_k: -12.45863681884527\n",
      "iteration: 699,the curren_loss: 2.910695781052283, the current_k: -12.470223923629746\n",
      "iteration: 700,the curren_loss: 2.9106239503702604, the current_k: -12.466433654984327\n",
      "iteration: 701,the curren_loss: 2.910552119688238, the current_k: -12.462643386338907\n",
      "iteration: 702,the curren_loss: 2.9107246106414975, the current_k: -12.458853117693488\n",
      "iteration: 703,the curren_loss: 2.910699880205995, the current_k: -12.470440222477965\n",
      "iteration: 704,the curren_loss: 2.9106280495239725, the current_k: -12.466649953832546\n",
      "iteration: 705,the curren_loss: 2.91055621884195, the current_k: -12.462859685187127\n",
      "iteration: 706,the curren_loss: 2.9107120792544015, the current_k: -12.459069416541707\n",
      "iteration: 707,the curren_loss: 2.910703979359707, the current_k: -12.470656521326184\n",
      "iteration: 708,the curren_loss: 2.910632148677685, the current_k: -12.466866252680765\n",
      "iteration: 709,the curren_loss: 2.9105603179956625, the current_k: -12.463075984035346\n",
      "iteration: 710,the curren_loss: 2.9106995478673063, the current_k: -12.459285715389926\n",
      "iteration: 711,the curren_loss: 2.910708078513419, the current_k: -12.470872820174403\n",
      "iteration: 712,the curren_loss: 2.910636247831397, the current_k: -12.467082551528984\n",
      "iteration: 713,the curren_loss: 2.910564417149375, the current_k: -12.463292282883565\n",
      "iteration: 714,the curren_loss: 2.910687016480211, the current_k: -12.459502014238145\n",
      "iteration: 715,the curren_loss: 2.9107121776671314, the current_k: -12.471089119022622\n",
      "iteration: 716,the curren_loss: 2.9106403469851094, the current_k: -12.467298850377203\n",
      "iteration: 717,the curren_loss: 2.910568516303087, the current_k: -12.463508581731784\n",
      "iteration: 718,the curren_loss: 2.910674485093115, the current_k: -12.459718313086364\n",
      "iteration: 719,the curren_loss: 2.9107162768208443, the current_k: -12.471305417870841\n",
      "iteration: 720,the curren_loss: 2.910644446138822, the current_k: -12.467515149225422\n",
      "iteration: 721,the curren_loss: 2.9105726154567995, the current_k: -12.463724880580003\n",
      "iteration: 722,the curren_loss: 2.91066195370602, the current_k: -12.459934611934584\n",
      "iteration: 723,the curren_loss: 2.910720375974556, the current_k: -12.47152171671906\n",
      "iteration: 724,the curren_loss: 2.910648545292534, the current_k: -12.467731448073641\n",
      "iteration: 725,the curren_loss: 2.9105767146105115, the current_k: -12.463941179428222\n",
      "iteration: 726,the curren_loss: 2.9106494223189237, the current_k: -12.460150910782803\n",
      "iteration: 727,the curren_loss: 2.9107244751282684, the current_k: -12.47173801556728\n",
      "iteration: 728,the curren_loss: 2.910652644446246, the current_k: -12.46794774692186\n",
      "iteration: 729,the curren_loss: 2.910580813764224, the current_k: -12.46415747827644\n",
      "iteration: 730,the curren_loss: 2.910636890931829, the current_k: -12.460367209631022\n",
      "iteration: 731,the curren_loss: 2.9107285742819804, the current_k: -12.471954314415498\n",
      "iteration: 732,the curren_loss: 2.910656743599958, the current_k: -12.468164045770079\n",
      "iteration: 733,the curren_loss: 2.910584912917936, the current_k: -12.46437377712466\n",
      "iteration: 734,the curren_loss: 2.9106243595447343, the current_k: -12.46058350847924\n",
      "iteration: 735,the curren_loss: 2.910732673435693, the current_k: -12.472170613263717\n",
      "iteration: 736,the curren_loss: 2.9106608427536704, the current_k: -12.468380344618298\n",
      "iteration: 737,the curren_loss: 2.9105890120716476, the current_k: -12.464590075972879\n",
      "iteration: 738,the curren_loss: 2.910611828157638, the current_k: -12.46079980732746\n",
      "iteration: 739,the curren_loss: 2.9107367725894044, the current_k: -12.472386912111936\n",
      "iteration: 740,the curren_loss: 2.910664941907383, the current_k: -12.468596643466517\n",
      "iteration: 741,the curren_loss: 2.910593111225361, the current_k: -12.464806374821098\n",
      "iteration: 742,the curren_loss: 2.910599296770543, the current_k: -12.461016106175679\n",
      "iteration: 743,the curren_loss: 2.9107408717431174, the current_k: -12.472603210960155\n",
      "iteration: 744,the curren_loss: 2.9106690410610945, the current_k: -12.468812942314736\n",
      "iteration: 745,the curren_loss: 2.9105972103790725, the current_k: -12.465022673669317\n",
      "iteration: 746,the curren_loss: 2.9105867653834476, the current_k: -12.461232405023898\n",
      "iteration: 747,the curren_loss: 2.91074497089683, the current_k: -12.472819509808375\n",
      "iteration: 748,the curren_loss: 2.910673140214807, the current_k: -12.469029241162955\n",
      "iteration: 749,the curren_loss: 2.910601309532785, the current_k: -12.465238972517536\n",
      "iteration: 750,the curren_loss: 2.9105742339963525, the current_k: -12.461448703872117\n",
      "iteration: 751,the curren_loss: 2.9107490700505414, the current_k: -12.473035808656594\n",
      "iteration: 752,the curren_loss: 2.9106772393685185, the current_k: -12.469245540011174\n",
      "iteration: 753,the curren_loss: 2.9106054086864974, the current_k: -12.465455271365755\n",
      "iteration: 754,the curren_loss: 2.9105617026092574, the current_k: -12.461665002720336\n",
      "iteration: 755,the curren_loss: 2.9107531692042534, the current_k: -12.473252107504813\n",
      "iteration: 756,the curren_loss: 2.9106813385222314, the current_k: -12.469461838859393\n",
      "iteration: 757,the curren_loss: 2.9106095078402094, the current_k: -12.465671570213974\n",
      "iteration: 758,the curren_loss: 2.9105491712221614, the current_k: -12.461881301568555\n",
      "iteration: 759,the curren_loss: 2.910757268357966, the current_k: -12.473468406353032\n",
      "iteration: 760,the curren_loss: 2.910685437675944, the current_k: -12.469678137707612\n",
      "iteration: 761,the curren_loss: 2.910613606993922, the current_k: -12.465887869062193\n",
      "iteration: 762,the curren_loss: 2.9105417763118995, the current_k: -12.462097600416774\n",
      "iteration: 763,the curren_loss: 2.9107562310348447, the current_k: -12.458307331771355\n",
      "iteration: 764,the curren_loss: 2.910689536829657, the current_k: -12.469894436555832\n",
      "iteration: 765,the curren_loss: 2.9106177061476335, the current_k: -12.466104167910412\n",
      "iteration: 766,the curren_loss: 2.910545875465611, the current_k: -12.462313899264993\n",
      "iteration: 767,the curren_loss: 2.91074369964775, the current_k: -12.458523630619574\n",
      "iteration: 768,the curren_loss: 2.9106936359833684, the current_k: -12.47011073540405\n",
      "iteration: 769,the curren_loss: 2.9106218053013464, the current_k: -12.466320466758631\n",
      "iteration: 770,the curren_loss: 2.910549974619324, the current_k: -12.462530198113212\n",
      "iteration: 771,the curren_loss: 2.9107311682606545, the current_k: -12.458739929467793\n",
      "iteration: 772,the curren_loss: 2.91069773513708, the current_k: -12.47032703425227\n",
      "iteration: 773,the curren_loss: 2.910625904455058, the current_k: -12.46653676560685\n",
      "iteration: 774,the curren_loss: 2.9105540737730355, the current_k: -12.462746496961431\n",
      "iteration: 775,the curren_loss: 2.91071863687356, the current_k: -12.458956228316012\n",
      "iteration: 776,the curren_loss: 2.910701834290793, the current_k: -12.470543333100489\n",
      "iteration: 777,the curren_loss: 2.910630003608771, the current_k: -12.46675306445507\n",
      "iteration: 778,the curren_loss: 2.9105581729267485, the current_k: -12.46296279580965\n",
      "iteration: 779,the curren_loss: 2.910706105486464, the current_k: -12.459172527164231\n",
      "iteration: 780,the curren_loss: 2.9107059334445045, the current_k: -12.470759631948708\n",
      "iteration: 781,the curren_loss: 2.910634102762483, the current_k: -12.466969363303289\n",
      "iteration: 782,the curren_loss: 2.91056227208046, the current_k: -12.46317909465787\n",
      "iteration: 783,the curren_loss: 2.9106935740993682, the current_k: -12.45938882601245\n",
      "iteration: 784,the curren_loss: 2.9107100325982174, the current_k: -12.470975930796927\n",
      "iteration: 785,the curren_loss: 2.910638201916195, the current_k: -12.467185662151508\n",
      "iteration: 786,the curren_loss: 2.9105663712341725, the current_k: -12.463395393506088\n",
      "iteration: 787,the curren_loss: 2.910681042712273, the current_k: -12.45960512486067\n",
      "iteration: 788,the curren_loss: 2.91071413175193, the current_k: -12.471192229645146\n",
      "iteration: 789,the curren_loss: 2.9106423010699065, the current_k: -12.467401960999727\n",
      "iteration: 790,the curren_loss: 2.910570470387885, the current_k: -12.463611692354307\n",
      "iteration: 791,the curren_loss: 2.9106685113251776, the current_k: -12.459821423708888\n",
      "iteration: 792,the curren_loss: 2.910718230905642, the current_k: -12.471408528493365\n",
      "iteration: 793,the curren_loss: 2.9106464002236194, the current_k: -12.467618259847946\n",
      "iteration: 794,the curren_loss: 2.9105745695415974, the current_k: -12.463827991202526\n",
      "iteration: 795,the curren_loss: 2.9106559799380824, the current_k: -12.460037722557107\n",
      "iteration: 796,the curren_loss: 2.910722330059354, the current_k: -12.471624827341584\n",
      "iteration: 797,the curren_loss: 2.910650499377332, the current_k: -12.467834558696165\n",
      "iteration: 798,the curren_loss: 2.9105786686953095, the current_k: -12.464044290050746\n",
      "iteration: 799,the curren_loss: 2.9106434485509864, the current_k: -12.460254021405326\n",
      "iteration: 800,the curren_loss: 2.9107264292130655, the current_k: -12.471841126189803\n",
      "iteration: 801,the curren_loss: 2.9106545985310435, the current_k: -12.468050857544384\n",
      "iteration: 802,the curren_loss: 2.910582767849022, the current_k: -12.464260588898965\n",
      "iteration: 803,the curren_loss: 2.910630917163891, the current_k: -12.460470320253545\n",
      "iteration: 804,the curren_loss: 2.910730528366778, the current_k: -12.472057425038022\n",
      "iteration: 805,the curren_loss: 2.9106586976847555, the current_k: -12.468267156392603\n",
      "iteration: 806,the curren_loss: 2.9105868670027335, the current_k: -12.464476887747184\n",
      "iteration: 807,the curren_loss: 2.9106183857767958, the current_k: -12.460686619101764\n",
      "iteration: 808,the curren_loss: 2.910734627520491, the current_k: -12.472273723886241\n",
      "iteration: 809,the curren_loss: 2.9106627968384684, the current_k: -12.468483455240822\n",
      "iteration: 810,the curren_loss: 2.9105909661564464, the current_k: -12.464693186595403\n",
      "iteration: 811,the curren_loss: 2.9106058543897, the current_k: -12.460902917949984\n",
      "iteration: 812,the curren_loss: 2.9107387266742024, the current_k: -12.47249002273446\n",
      "iteration: 813,the curren_loss: 2.9106668959921804, the current_k: -12.468699754089041\n",
      "iteration: 814,the curren_loss: 2.910595065310158, the current_k: -12.464909485443622\n",
      "iteration: 815,the curren_loss: 2.9105933230026055, the current_k: -12.461119216798203\n",
      "iteration: 816,the curren_loss: 2.910742825827915, the current_k: -12.47270632158268\n",
      "iteration: 817,the curren_loss: 2.910670995145893, the current_k: -12.46891605293726\n",
      "iteration: 818,the curren_loss: 2.9105991644638705, the current_k: -12.46512578429184\n",
      "iteration: 819,the curren_loss: 2.9105807916155095, the current_k: -12.461335515646422\n",
      "iteration: 820,the curren_loss: 2.910746924981626, the current_k: -12.472922620430898\n",
      "iteration: 821,the curren_loss: 2.910675094299605, the current_k: -12.469132351785479\n",
      "iteration: 822,the curren_loss: 2.910603263617583, the current_k: -12.46534208314006\n",
      "iteration: 823,the curren_loss: 2.9105682602284153, the current_k: -12.46155181449464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 824,the curren_loss: 2.9107510241353394, the current_k: -12.473138919279117\n",
      "iteration: 825,the curren_loss: 2.910679193453317, the current_k: -12.469348650633698\n",
      "iteration: 826,the curren_loss: 2.910607362771294, the current_k: -12.465558381988279\n",
      "iteration: 827,the curren_loss: 2.9105557288413193, the current_k: -12.46176811334286\n",
      "iteration: 828,the curren_loss: 2.910755123289051, the current_k: -12.473355218127336\n",
      "iteration: 829,the curren_loss: 2.9106832926070294, the current_k: -12.469564949481917\n",
      "iteration: 830,the curren_loss: 2.910611461925007, the current_k: -12.465774680836498\n",
      "iteration: 831,the curren_loss: 2.9105431974542233, the current_k: -12.461984412191079\n",
      "iteration: 832,the curren_loss: 2.910759222442764, the current_k: -12.473571516975555\n",
      "iteration: 833,the curren_loss: 2.9106873917607414, the current_k: -12.469781248330136\n",
      "iteration: 834,the curren_loss: 2.910615561078719, the current_k: -12.465990979684717\n",
      "iteration: 835,the curren_loss: 2.910543730396697, the current_k: -12.462200711039298\n",
      "iteration: 836,the curren_loss: 2.9107502572669075, the current_k: -12.458410442393879\n",
      "iteration: 837,the curren_loss: 2.9106914909144534, the current_k: -12.469997547178355\n",
      "iteration: 838,the curren_loss: 2.910619660232432, the current_k: -12.466207278532936\n",
      "iteration: 839,the curren_loss: 2.910547829550409, the current_k: -12.462417009887517\n",
      "iteration: 840,the curren_loss: 2.9107377258798124, the current_k: -12.458626741242098\n",
      "iteration: 841,the curren_loss: 2.910695590068166, the current_k: -12.470213846026574\n",
      "iteration: 842,the curren_loss: 2.9106237593861435, the current_k: -12.466423577381155\n",
      "iteration: 843,the curren_loss: 2.910551928704121, the current_k: -12.462633308735736\n",
      "iteration: 844,the curren_loss: 2.910725194492717, the current_k: -12.458843040090317\n",
      "iteration: 845,the curren_loss: 2.9106996892218784, the current_k: -12.470430144874793\n",
      "iteration: 846,the curren_loss: 2.9106278585398564, the current_k: -12.466639876229374\n",
      "iteration: 847,the curren_loss: 2.910556027857834, the current_k: -12.462849607583955\n",
      "iteration: 848,the curren_loss: 2.9107126631056213, the current_k: -12.459059338938536\n",
      "iteration: 849,the curren_loss: 2.910703788375591, the current_k: -12.470646443723012\n",
      "iteration: 850,the curren_loss: 2.9106319576935684, the current_k: -12.466856175077593\n",
      "iteration: 851,the curren_loss: 2.910560127011546, the current_k: -12.463065906432174\n",
      "iteration: 852,the curren_loss: 2.9107001317185257, the current_k: -12.459275637786755\n",
      "iteration: 853,the curren_loss: 2.910707887529303, the current_k: -12.470862742571232\n",
      "iteration: 854,the curren_loss: 2.91063605684728, the current_k: -12.467072473925812\n",
      "iteration: 855,the curren_loss: 2.910564226165258, the current_k: -12.463282205280393\n",
      "iteration: 856,the curren_loss: 2.9106876003314306, the current_k: -12.459491936634974\n",
      "iteration: 857,the curren_loss: 2.9107119866830153, the current_k: -12.47107904141945\n",
      "iteration: 858,the curren_loss: 2.910640156000993, the current_k: -12.467288772774031\n",
      "iteration: 859,the curren_loss: 2.9105683253189705, the current_k: -12.463498504128612\n",
      "iteration: 860,the curren_loss: 2.9106750689443346, the current_k: -12.459708235483193\n",
      "iteration: 861,the curren_loss: 2.9107160858367274, the current_k: -12.47129534026767\n",
      "iteration: 862,the curren_loss: 2.910644255154705, the current_k: -12.46750507162225\n",
      "iteration: 863,the curren_loss: 2.9105724244726825, the current_k: -12.463714802976831\n",
      "iteration: 864,the curren_loss: 2.91066253755724, the current_k: -12.459924534331412\n",
      "iteration: 865,the curren_loss: 2.910720184990439, the current_k: -12.471511639115889\n",
      "iteration: 866,the curren_loss: 2.9106483543084174, the current_k: -12.46772137047047\n",
      "iteration: 867,the curren_loss: 2.910576523626395, the current_k: -12.46393110182505\n",
      "iteration: 868,the curren_loss: 2.910650006170145, the current_k: -12.460140833179631\n",
      "iteration: 869,the curren_loss: 2.9107242841441514, the current_k: -12.471727937964108\n",
      "iteration: 870,the curren_loss: 2.91065245346213, the current_k: -12.467937669318689\n",
      "iteration: 871,the curren_loss: 2.910580622780108, the current_k: -12.46414740067327\n",
      "iteration: 872,the curren_loss: 2.910637474783049, the current_k: -12.46035713202785\n",
      "iteration: 873,the curren_loss: 2.910728383297864, the current_k: -12.471944236812327\n",
      "iteration: 874,the curren_loss: 2.910656552615842, the current_k: -12.468153968166908\n",
      "iteration: 875,the curren_loss: 2.9105847219338186, the current_k: -12.464363699521488\n",
      "iteration: 876,the curren_loss: 2.910624943395953, the current_k: -12.46057343087607\n",
      "iteration: 877,the curren_loss: 2.910732482451577, the current_k: -12.472160535660546\n",
      "iteration: 878,the curren_loss: 2.910660651769554, the current_k: -12.468370267015127\n",
      "iteration: 879,the curren_loss: 2.9105888210875315, the current_k: -12.464579998369707\n",
      "iteration: 880,the curren_loss: 2.9106124120088586, the current_k: -12.460789729724288\n",
      "iteration: 881,the curren_loss: 2.910736581605289, the current_k: -12.472376834508765\n",
      "iteration: 882,the curren_loss: 2.9106647509232655, the current_k: -12.468586565863346\n",
      "iteration: 883,the curren_loss: 2.9105929202412435, the current_k: -12.464796297217926\n",
      "iteration: 884,the curren_loss: 2.910599880621763, the current_k: -12.461006028572507\n",
      "iteration: 885,the curren_loss: 2.9107406807590004, the current_k: -12.472593133356984\n",
      "iteration: 886,the curren_loss: 2.910668850076978, the current_k: -12.468802864711565\n",
      "iteration: 887,the curren_loss: 2.9105970193949564, the current_k: -12.465012596066146\n",
      "iteration: 888,the curren_loss: 2.910587349234667, the current_k: -12.461222327420726\n",
      "iteration: 889,the curren_loss: 2.9107447799127124, the current_k: -12.472809432205203\n",
      "iteration: 890,the curren_loss: 2.9106729492306913, the current_k: -12.469019163559784\n",
      "iteration: 891,the curren_loss: 2.910601118548669, the current_k: -12.465228894914365\n",
      "iteration: 892,the curren_loss: 2.9105748178475714, the current_k: -12.461438626268945\n",
      "iteration: 893,the curren_loss: 2.9107488790664253, the current_k: -12.473025731053422\n",
      "iteration: 894,the curren_loss: 2.9106770483844033, the current_k: -12.469235462408003\n",
      "iteration: 895,the curren_loss: 2.91060521770238, the current_k: -12.465445193762584\n",
      "iteration: 896,the curren_loss: 2.9105622864604763, the current_k: -12.461654925117164\n",
      "iteration: 897,the curren_loss: 2.9107529782201373, the current_k: -12.473242029901641\n",
      "iteration: 898,the curren_loss: 2.910681147538115, the current_k: -12.469451761256222\n",
      "iteration: 899,the curren_loss: 2.9106093168560925, the current_k: -12.465661492610803\n",
      "iteration: 900,the curren_loss: 2.910549755073381, the current_k: -12.461871223965383\n",
      "iteration: 901,the curren_loss: 2.9107570773738494, the current_k: -12.47345832874986\n",
      "iteration: 902,the curren_loss: 2.9106852466918274, the current_k: -12.469668060104441\n",
      "iteration: 903,the curren_loss: 2.910613416009805, the current_k: -12.465877791459022\n",
      "iteration: 904,the curren_loss: 2.9105415853277825, the current_k: -12.462087522813603\n",
      "iteration: 905,the curren_loss: 2.910756814886065, the current_k: -12.458297254168183\n",
      "iteration: 906,the curren_loss: 2.9106893458455394, the current_k: -12.46988435895266\n",
      "iteration: 907,the curren_loss: 2.910617515163517, the current_k: -12.46609409030724\n",
      "iteration: 908,the curren_loss: 2.910545684481495, the current_k: -12.462303821661822\n",
      "iteration: 909,the curren_loss: 2.91074428349897, the current_k: -12.458513553016402\n",
      "iteration: 910,the curren_loss: 2.910693444999251, the current_k: -12.470100657800879\n",
      "iteration: 911,the curren_loss: 2.91062161431723, the current_k: -12.46631038915546\n",
      "iteration: 912,the curren_loss: 2.910549783635207, the current_k: -12.46252012051004\n",
      "iteration: 913,the curren_loss: 2.910731752111874, the current_k: -12.458729851864621\n",
      "iteration: 914,the curren_loss: 2.910697544152964, the current_k: -12.470316956649098\n",
      "iteration: 915,the curren_loss: 2.9106257134709415, the current_k: -12.466526688003679\n",
      "iteration: 916,the curren_loss: 2.910553882788919, the current_k: -12.46273641935826\n",
      "iteration: 917,the curren_loss: 2.910719220724779, the current_k: -12.45894615071284\n",
      "iteration: 918,the curren_loss: 2.910701643306676, the current_k: -12.470533255497317\n",
      "iteration: 919,the curren_loss: 2.9106298126246535, the current_k: -12.466742986851898\n",
      "iteration: 920,the curren_loss: 2.910557981942632, the current_k: -12.462952718206479\n",
      "iteration: 921,the curren_loss: 2.910706689337683, the current_k: -12.45916244956106\n",
      "iteration: 922,the curren_loss: 2.910705742460388, the current_k: -12.470749554345536\n",
      "iteration: 923,the curren_loss: 2.9106339117783664, the current_k: -12.466959285700117\n",
      "iteration: 924,the curren_loss: 2.9105620810963435, the current_k: -12.463169017054698\n",
      "iteration: 925,the curren_loss: 2.9106941579505885, the current_k: -12.459378748409279\n",
      "iteration: 926,the curren_loss: 2.910709841614101, the current_k: -12.470965853193755\n",
      "iteration: 927,the curren_loss: 2.910638010932078, the current_k: -12.467175584548336\n",
      "iteration: 928,the curren_loss: 2.9105661802500555, the current_k: -12.463385315902917\n",
      "iteration: 929,the curren_loss: 2.9106816265634925, the current_k: -12.459595047257498\n",
      "iteration: 930,the curren_loss: 2.9107139407678124, the current_k: -12.471182152041974\n",
      "iteration: 931,the curren_loss: 2.9106421100857904, the current_k: -12.467391883396555\n",
      "iteration: 932,the curren_loss: 2.9105702794037684, the current_k: -12.463601614751136\n",
      "iteration: 933,the curren_loss: 2.9106690951763974, the current_k: -12.459811346105717\n",
      "iteration: 934,the curren_loss: 2.9107180399215244, the current_k: -12.471398450890193\n",
      "iteration: 935,the curren_loss: 2.9106462092395025, the current_k: -12.467608182244774\n",
      "iteration: 936,the curren_loss: 2.9105743785574805, the current_k: -12.463817913599355\n",
      "iteration: 937,the curren_loss: 2.9106565637893014, the current_k: -12.460027644953936\n",
      "iteration: 938,the curren_loss: 2.9107221390752374, the current_k: -12.471614749738412\n",
      "iteration: 939,the curren_loss: 2.9106503083932154, the current_k: -12.467824481092993\n",
      "iteration: 940,the curren_loss: 2.910578477711193, the current_k: -12.464034212447574\n",
      "iteration: 941,the curren_loss: 2.9106440324022067, the current_k: -12.460243943802155\n",
      "iteration: 942,the curren_loss: 2.910726238228949, the current_k: -12.471831048586631\n",
      "iteration: 943,the curren_loss: 2.9106544075469274, the current_k: -12.468040779941212\n",
      "iteration: 944,the curren_loss: 2.910582576864905, the current_k: -12.464250511295793\n",
      "iteration: 945,the curren_loss: 2.9106315010151107, the current_k: -12.460460242650374\n",
      "iteration: 946,the curren_loss: 2.9107303373826614, the current_k: -12.47204734743485\n",
      "iteration: 947,the curren_loss: 2.9106585067006394, the current_k: -12.468257078789431\n",
      "iteration: 948,the curren_loss: 2.9105866760186165, the current_k: -12.464466810144012\n",
      "iteration: 949,the curren_loss: 2.9106189696280156, the current_k: -12.460676541498593\n",
      "iteration: 950,the curren_loss: 2.910734436536374, the current_k: -12.47226364628307\n",
      "iteration: 951,the curren_loss: 2.910662605854351, the current_k: -12.46847337763765\n",
      "iteration: 952,the curren_loss: 2.910590775172329, the current_k: -12.464683108992231\n",
      "iteration: 953,the curren_loss: 2.910606438240921, the current_k: -12.460892840346812\n",
      "iteration: 954,the curren_loss: 2.9107385356900854, the current_k: -12.472479945131289\n",
      "iteration: 955,the curren_loss: 2.910666705008064, the current_k: -12.46868967648587\n",
      "iteration: 956,the curren_loss: 2.9105948743260415, the current_k: -12.46489940784045\n",
      "iteration: 957,the curren_loss: 2.9105939068538254, the current_k: -12.461109139195031\n",
      "iteration: 958,the curren_loss: 2.9107426348437984, the current_k: -12.472696243979508\n",
      "iteration: 959,the curren_loss: 2.910670804161776, the current_k: -12.468905975334089\n",
      "iteration: 960,the curren_loss: 2.910598973479754, the current_k: -12.46511570668867\n",
      "iteration: 961,the curren_loss: 2.9105813754667293, the current_k: -12.46132543804325\n",
      "iteration: 962,the curren_loss: 2.9107467339975104, the current_k: -12.472912542827727\n",
      "iteration: 963,the curren_loss: 2.910674903315488, the current_k: -12.469122274182308\n",
      "iteration: 964,the curren_loss: 2.9106030726334655, the current_k: -12.465332005536888\n",
      "iteration: 965,the curren_loss: 2.910568844079634, the current_k: -12.46154173689147\n",
      "iteration: 966,the curren_loss: 2.910750833151223, the current_k: -12.473128841675946\n",
      "iteration: 967,the curren_loss: 2.9106790024692004, the current_k: -12.469338573030527\n",
      "iteration: 968,the curren_loss: 2.910607171787178, the current_k: -12.465548304385107\n",
      "iteration: 969,the curren_loss: 2.9105563126925387, the current_k: -12.461758035739688\n",
      "iteration: 970,the curren_loss: 2.9107549323049353, the current_k: -12.473345140524165\n",
      "iteration: 971,the curren_loss: 2.910683101622913, the current_k: -12.469554871878746\n",
      "iteration: 972,the curren_loss: 2.9106112709408896, the current_k: -12.465764603233326\n",
      "iteration: 973,the curren_loss: 2.910543781305443, the current_k: -12.461974334587907\n",
      "iteration: 974,the curren_loss: 2.9107590314586473, the current_k: -12.473561439372384\n",
      "iteration: 975,the curren_loss: 2.910687200776625, the current_k: -12.469771170726965\n",
      "iteration: 976,the curren_loss: 2.910615370094603, the current_k: -12.465980902081546\n",
      "iteration: 977,the curren_loss: 2.9105435394125805, the current_k: -12.462190633436126\n",
      "iteration: 978,the curren_loss: 2.9107508411181264, the current_k: -12.458400364790707\n",
      "iteration: 979,the curren_loss: 2.9106912999303374, the current_k: -12.469987469575184\n",
      "iteration: 980,the curren_loss: 2.910619469248315, the current_k: -12.466197200929765\n",
      "iteration: 981,the curren_loss: 2.9105476385662925, the current_k: -12.462406932284345\n",
      "iteration: 982,the curren_loss: 2.9107383097310318, the current_k: -12.458616663638926\n",
      "iteration: 983,the curren_loss: 2.9106953990840494, the current_k: -12.470203768423403\n",
      "iteration: 984,the curren_loss: 2.910623568402027, the current_k: -12.466413499777984\n",
      "iteration: 985,the curren_loss: 2.910551737720005, the current_k: -12.462623231132564\n",
      "iteration: 986,the curren_loss: 2.9107257783439358, the current_k: -12.458832962487145\n",
      "iteration: 987,the curren_loss: 2.9106994982377614, the current_k: -12.470420067271622\n",
      "iteration: 988,the curren_loss: 2.9106276675557394, the current_k: -12.466629798626203\n",
      "iteration: 989,the curren_loss: 2.910555836873717, the current_k: -12.462839529980783\n",
      "iteration: 990,the curren_loss: 2.910713246956841, the current_k: -12.459049261335364\n",
      "iteration: 991,the curren_loss: 2.910703597391474, the current_k: -12.470636366119841\n",
      "iteration: 992,the curren_loss: 2.9106317667094515, the current_k: -12.466846097474422\n",
      "iteration: 993,the curren_loss: 2.9105599360274295, the current_k: -12.463055828829003\n",
      "iteration: 994,the curren_loss: 2.9107007155697455, the current_k: -12.459265560183583\n",
      "iteration: 995,the curren_loss: 2.9107076965451864, the current_k: -12.47085266496806\n",
      "iteration: 996,the curren_loss: 2.910635865863164, the current_k: -12.46706239632264\n",
      "iteration: 997,the curren_loss: 2.9105640351811415, the current_k: -12.463272127677222\n",
      "iteration: 998,the curren_loss: 2.91068818418265, the current_k: -12.459481859031802\n",
      "iteration: 999,the curren_loss: 2.9107117956988975, the current_k: -12.471068963816279\n",
      "iteration: 1000,the curren_loss: 2.910639965016876, the current_k: -12.46727869517086\n"
     ]
    }
   ],
   "source": [
    "k = random.random() * 20 - 10\n",
    "b = random.random() * 20 - 10\n",
    "learning_rate = 1e-2\n",
    "iteration_numbers = 1000\n",
    "losses = []\n",
    "\n",
    "for i in range(iteration_numbers):\n",
    "    current_price_parameters = [price(r, k, b) for r in X]\n",
    "    current_loss = loss(y, current_price_parameters)\n",
    "    losses.append(current_loss)\n",
    "    print('iteration: {},the curren_loss: {}, the current_k: {}'.format(i+1, current_loss, k))\n",
    "    \n",
    "    gradient_k = partial_derivative_k(X,y,current_price_parameters)\n",
    "    k = k + (-gradient_k * learning_rate)\n",
    "best_k = k \n",
    "best_b = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x230cd3e8e08>]"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(iteration_numbers)),losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x230cd4b9808>"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAATCklEQVR4nO3df4wc5X3H8c8X+wznhNyh+qIU28REISjIsWKyRKRIScvRggAbRCOXVG5LEuVo2kJEI7dGqYzlJgqq25JYjVoMpVVbGrhSl5iU1EkNNC2qEWtMD4NDRIHgs0Fc2vrU1kd92N/+MXtwXu+Pudtnfjy775d02tvZuZlnbmc/++zzPPuMubsAAPE6regCAAA6Q5ADQOQIcgCIHEEOAJEjyAEgcguL2OmSJUt8xYoVRewaAKK1d+/eH7v7UP3yQoJ8xYoVqlarRewaAKJlZj9qtJymFQCIHEEOAJEjyAEgcgQ5AESOIAeAyMUZ5GOj0h0rpc2Dye3YaNElAoDCFDL8sCNjo9JDN0vTU8n9yYPJfUlata64cgFAQeKrke/e8naIz5ieSpYDQA+KL8gnx+e2HAC6XHxBPrBsbssBoMvFF+TDm6S+/pOX9fUnywGgB8UX5KvWSWu2SQPLJVlyu2bbqR2djGwB0CPiG7UiJaHdaoQKI1sA9JD4auRpMLIFQA/pziBnZAuAHtKdQc7IFgA9pDuDnJEtAHpIdwZ52pEtANAF4hy1kka7kS0A0CW6s0YOAD0kSJCb2S1m9qyZ7Tezb5rZGSG2CwBor+MgN7Olkm6WVHH3lZIWSLq+0+0CANIJ1bSyUFK/mS2UtFjS4UDbBQC00XGQu/shSb8v6RVJr0qadPfvdrpdAEA6IZpWzpJ0jaRzJZ0t6R1mtr7BeiNmVjWz6sTERKe7BQDUhGhauUzSS+4+4e7TknZI+qn6ldx9u7tX3L0yNDQUYLcAAClMkL8i6WIzW2xmJmlY0oEA2wUApBCijfwJSQ9IekrSM7Vtbu90uwCAdIJ8s9Pdb5N0W4htRWVsNJkad3I8mZBreBPfJgWQu+79in7WuHgFgJLgK/rzxcUrAJQEQT5fXLwCQEkQ5PPFxSsAlARBPl9cvAJASRDk88XFKwCUBKNWOsHFKwCUADVyAIgcQQ4AkSPIASByBDkARI4gB4DIEeQAEDmCHAAiR5ADQOQIcgCIHEEOAJEjyAEgcgQ5AESOIAeAyBHkABA5ghwAIkeQA0DkCHIAiBxBDgCRCxLkZjZoZg+Y2Q/M7ICZfSzEdgEA7YW6ZufXJf2Du3/SzBZJWhxouwCANjoOcjN7l6SPS7pBktz9mKRjnW4XAJBOiKaV90makPRnZrbPzO42s3fUr2RmI2ZWNbPqxMREgN0CAKQwQb5Q0oWS/tjdV0v6X0kb61dy9+3uXnH3ytDQUIDdAgCkMEE+Lmnc3Z+o3X9ASbADAHLQcZC7+2uSDprZ+bVFw5Ke63S7AIB0Qo1auUnSvbURKy9K+nSg7QIA2ggS5O7+tKRKiG0BAOaGb3YCQOQIcgCIHEEOAJEjyNHe2Kh0x0pp82ByOzZadIkAzBJq1Aq61dio9NDN0vRUcn/yYHJfklatK65cAN5CjRyt7d7ydojPmJ5KlgMoBYIcrU2Oz205gNwR5GhtYNnclgPIHUGO1oY3SX39Jy/r60+WAygFghytrVonrdkmDSyXZMntmm10dAIlwqgVtLdqHcENlBg1cgCIHEEOAJEjyAEgcgQ5AESOIAeAyBHkABA5ghwAIkeQA0DkCHIUi7nOgY7xzU4Uh7nOgSCokaM4zHUOBEGQozjMdQ4EQZCjOMx1DgRBkKM4zHUOBBEsyM1sgZntM7Nvh9omuhxznQNBhBy18gVJByS9K+A20e2Y6xzoWJAauZktk3SVpLtDbA8AkF6oppWvSfotSSearWBmI2ZWNbPqxMREoN0CADoOcjO7WtLr7r631Xruvt3dK+5eGRoa6nS3AICaEDXySyStNbOXJd0n6VIz+6sA2wUApNBxkLv7re6+zN1XSLpe0iPuvr7jkgEAUmEcOQBELuikWe7+mKTHQm4TANAaNXIAiBxBDgCRI8gBIHIEOXoLVyRCF+IKQegdXJEIXYoaOXoHVyRClyLI0Tu4IhG6FEGO3sEVidClCHL0jnZXJKIjFJGisxO9Y6ZDc/eWpDllYFkS4qvW0RGKqBHk6C3NrkjUqiOUIEfJ0bQCSHSEImoEOSDREYqoEeSA1L4jFCgxghyQknbwNdukgeWSLLlds432cUSBzk5gRrOOUKDkqJEDnWDsOUqAGjkwX4w9R0lQIwfmi0m4UBIEOTBfjD1HSRDkwHwx9hwlQZAD88XYc5QEQQ7MV9qx54xsQcbM3XPfaaVS8Wq1mvt+gdzVj2yRJJlU+Yx09R8WVizEycz2unulfjk1ciBLjUa2yKXqPdTMEUzHQW5my83sUTM7YGbPmtkXQhQM6ApNR7A4wxQRTIga+ZuSvujuH5R0saRfN7MLAmwXiF+rESwMU0QgHQe5u7/q7k/Vfv9vSQckLe10u0BXGN4kyRo/xjBFBBK0jdzMVkhaLemJBo+NmFnVzKoTExMhdwuU16p1ScdmfZhzrVAEFGzUipm9U9I/SfqKu+9otS6jVtBzxkbTXStUUhL6ngxnnFkPUPNRK0EmzTKzPkl/K+nediEO9KS5XCtUtcoVk3AhpRCjVkzSn0o64O4MjAXmol2HJ5NwIYUQbeSXSPolSZea2dO1nysDbBfofmk6PBndgjY6blpx939R0255AC0Nb2rQRl6H0S1og292AkU6ab4WqeXoFqAJrhAEFG12R2iz0S1ACwQ5UCZcABrzQNMKAESOIAeAyBHkABA5ghwAIkeQA0DkCHIAiBxBDgCRi3Ic+YP7Dmnrrud1+MiUzh7s14bLz9e1q/O/lkVZyoHy41xBlqIL8gf3HdKtO57R1PRxSdKhI1O6dcczkpTrC6Ms5UD5ca4ga9E1rWzd9fxbL4gZU9PHtXXX8z1Zjjw8uO+QLrn9EZ278e91ye2P6MF9h4ouUlR66VxBMaKrkR8+0niWuGbLu70cWaM22bleOVdQnOhq5GcP9s9pebeXI2vUJjvX7ecKn9iKF12Qb7j8fPX3LThpWX/fAm24/PyeLEfWeqk2mVUgdfO5MvOJ7dCRKbne/sRGmOcruiC/dvVSffW6D2npYL9M0tLBfn31ug/l/jG/LOXIWrfXJmdkHUinL3z7pXbW4r5ynitjo9IdK6XNg8nt2GjbP+ETWzlE10YuJSFahhdBWcqRpQ2Xn39SG7kUtjZZlmF5rQKpVXnalb++j0GS3pg+Ef4AOjU2qje/dZMWHn8juT95MLkvtZxWt5c+sc1HXud3lEGO/MycdFmcjGXqSJ1PIKUp/3zfIPJ29DubtHgmxGsWHn8jWd4iyM8e7NehBv+jGD6xZRWyM9s9dGRKJslry7M8vwlytJXVJ48iQq7Zi3c+gZSm/GneIMrwqeSMqdfmtHxG1p/YQss6ZOvf3L3u8azO7+jayNE98v5Y3qodfD4dkmnK366PoVGZbrn/aa3IeQTI4RM/MaflM2LqK5r9v5aah2wnGr2518vi/CbIUZi8O1Lb1aDnGkhpyt/uDaJRmepriXmE+d2L1uuoLzpp2VFfpLsXrW/7t9euXqrHN16ql26/So9vvLSUIS7lE7Jp/j6L85sgR2HyHpbXrgY910BKU/52bxDtXvh5jQD58FUj2uQjGj+xRCfcNH5iiTb5iD581Ujm+85LHiHb7u+zOr9pI0dhsuxIbSR0x1za8rfqY2hWptnyGAGSlO/X9Au7hlM9F0/uvFPLn9qqd/uEXrchHbxwgy5ae2Pm5exEu/91iJBt1Gcw0xa/NMPz29zrW4qyV6lUvFqt5r5f9LZGQwH7+xYU2qbbqEz1lg726/GNl+ZYqtae3HmnVu79HfXbsbeWTfki7f/Il0sd5o3+1/UhK3Vesciy89rM9rp75ZTlIYLczK6Q9HVJCyTd7e63t1o/jyAvw0gAlE8Zz4tmIymk4t9oGnlt8/v1Hk2cstwl2cByaXhTy7HnRWr1/Jfxjb5eZkFuZgsk/VDSz0oal/SkpE+5+3PN/ibrII/hCQEaKeMbTb0Ttw3oNGuxQl+/tGZbacO8mUtuf6Rh00uZPhE1C/IQbeQflfSCu79Y29F9kq6R1DTIsxbLlzCAejF8W/h1G2pYI3/L9JS0e0t0QR7zt1RDjFpZKungrPvjtWUnMbMRM6uaWXViosVJEEDMTwhQdgcv3KCpuqGKp5gcz6cwAcU8r1CIIG/0IeuU9hp33+7uFXevDA0NBdhtczE/IUDZXbT2Ru3/yJf1mobUtGV2YFmuZQoh5lkqQwT5uKTls+4vk3Q4wHbnLeYnBIjBRWtv1Hs2vyD7+buSNvHZ+vqTDs/IxPQt1Xoh2siflHSemZ0r6ZCk6yX9YoDtzlve45OBnjXTDr57S9KcMrCs1KNW2omhj6KRUMMPr5T0NSXDD+9x96+0Wp9x5AAwd1mOWpG7Pyzp4RDbAgDMDXOtAEDkCHIAiBxBDgCRI8gBIHIEOQBEjiAHgMgR5AAQOYIcACJHkANA5AhyAIgcQQ4AkSPIASByBDkARI4gB4DIEeQAEDmCHAAiR5ADQOQIcgCIHEEOAJEjyAEgcgQ5gN4xNirdsVLaPJjcjo0WXaIgCHIAvWFsVHroZmnyoCRPbneMSJsHog91ghxAb9i9RZqeqlvoyc3kwSTkIw1zghxAb5gcb/349FQS9hEiyAH0hoFl7ddpF/Yl1VGQm9lWM/uBmY2Z2d+Z2WCoggFAUMObpL7+1uv0nxVlZ2inNfLvSVrp7qsk/VDSrZ0XCQAysGqdtGabNLC8tsBOfvy0PunY/5zcGRpJu3lHQe7u33X3N2t390hK8dkFAAqyap10y35p86R03fZaqFtye/qZ0vFjJ68fSbv5woDb+oyk+5s9aGYjkkYk6Zxzzgm4WwCYh1Xrkp8Zm5u0DEfQbt62Rm5m/2hm+xv8XDNrnS9JelPSvc224+7b3b3i7pWhoaEwpQeAUJp1hqbpJC1Y2xq5u1/W6nEz+xVJV0sadncPVTAAyNXwpqRNfPZY877+ZHnJddS0YmZXSPptSZ9w96NhigQABZhpZtm9JWlOGViWhPjs5peS6rSN/I8knS7pe2YmSXvc/Vc7LhUAFKG+3TwSHQW5u78/VEEAAPPDNzsBIHIEOQBEjiAHgJAKmPM85BeCAKC3zcx5PjOEceZr/lKmnajUyAEglEZznk9PSTs+l2ntnCAHgFBafZ0/w0m4CHIACKXd1/kzmoSLIAeAUNLMeZ7BJFwEOQCEcsqc5w1kMAkXQQ4AIc3MeX7dXafWzjOahIsgB4AsnFQ7r128Ys22TIYhMo4cALKS0yRc1MgBIHIEOQBEjiAHgMgR5AAQOYIcACJnRVwv2cwmJP0o9x0Xb4mkHxddiIL08rFLHD/HH+b43+vuQ/ULCwnyXmVmVXevFF2OIvTysUscP8ef7fHTtAIAkSPIASByBHm+thddgAL18rFLHD/HnyHayAEgctTIASByBDkARI4gD8zMrjCz583sBTPb2ODx3zSz58xszMx2m9l7iyhnVtod/6z1PmlmbmZdNSQtzfGb2braOfCsmf113mXMUorz/xwze9TM9tVeA1cWUc4smNk9Zva6me1v8riZ2bba/2bMzC4MtnN35yfQj6QFkv5d0vskLZL0b5IuqFvnZyQtrv3+eUn3F13uPI+/tt6Zkr4vaY+kStHlzvn5P0/SPkln1e6/u+hy53z82yV9vvb7BZJeLrrcAY//45IulLS/yeNXSvqOJJN0saQnQu2bGnlYH5X0gru/6O7HJN0n6ZrZK7j7o+5+tHZ3j6Tw130qTtvjr/ldSb8n6Y08C5eDNMf/OUnfcPf/kiR3fz3nMmYpzfG7pHfVfh+QdDjH8mXK3b8v6T9brHKNpL/wxB5Jg2b2kyH2TZCHtVTSwVn3x2vLmvmsknfobtH2+M1staTl7v7tPAuWkzTP/wckfcDMHjezPWZ2RW6ly16a498sab2ZjUt6WNJN+RStFOaaD6lxhaCwrMGyhuM7zWy9pIqkT2Raony1PH4zO03SHZJuyKtAOUvz/C9U0rzy00o+jf2zma109yMZly0PaY7/U5L+3N3/wMw+Jukva8d/IvviFS51PswVNfKwxiXNvnz2MjX46Ghml0n6kqS17v5/OZUtD+2O/0xJKyU9ZmYvK2kn3NlFHZ5pnv9xSd9y92l3f0nS80qCvRukOf7PShqVJHf/V0lnKJlQqhekyof5IMjDelLSeWZ2rpktknS9pJ2zV6g1LdypJMS7qX1UanP87j7p7kvcfYW7r1DSR7DW3avFFDe4ts+/pAeVdHjLzJYoaWp5MddSZifN8b8iaViSzOyDSoJ8ItdSFmenpF+ujV65WNKku78aYsM0rQTk7m+a2W9I2qWkB/8ed3/WzLZIqrr7TklbJb1T0t+YmSS94u5rCyt0QCmPv2ulPP5dkn7OzJ6TdFzSBnf/j+JKHU7K4/+ipLvM7BYlzQo3eG1IR+zM7JtKmsyW1PoAbpPUJ0nu/idK+gSulPSCpKOSPh1s313yPwSAnkXTCgBEjiAHgMgR5AAQOYIcACJHkANA5AhyAIgcQQ4Akft/8nbpD9+Ibc4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "price_use_best_parameters = [price(r, best_k, best_b) for r in X]\n",
    "\n",
    "plt.scatter(X,y)\n",
    "plt.scatter(X,price_use_best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "+ 是否将Loss改成了“绝对值”(3')\n",
    "+ 是否完成了偏导的重新定义(5')\n",
    "+ 新的模型Loss是否能够收敛 (11’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
